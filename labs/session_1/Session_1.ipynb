{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlr112/WebScicence_FinalProject/blob/main/labs/session_1/Session_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8xQU9M1D1b7n"
      },
      "outputs": [],
      "source": [
        "# !git config --global user.email \"vlr112@alumni.ku.dk\"\n",
        "# !git config --global user.name \"vlr112\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEnlbhpW1b-H",
        "outputId": "0269b000-9ad3-457f-81c4-3ac9e28a8644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'WebScicence_FinalProject'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 88 (delta 40), reused 37 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://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@github.com/vlr112/WebScicence_FinalProject.git\n",
        "# note: remove token info before submitting project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNX8ZqL1cBR",
        "outputId": "a86434b0-c6a2-4c6d-b372-5ee8bbce017c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/WebScicence_FinalProject/labs/session_1\n"
          ]
        }
      ],
      "source": [
        "# %cd WebScicence_FinalProject/labs/session_1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-w_20vf30cX4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "from pandas.util import hash_pandas_object\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "#######\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wSqrrPw00cX7"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9PqdMS0cX9"
      },
      "source": [
        "# Familiarize Yourself with the Dataset\n",
        "In the lab sessions, we will work with the \"All Beauty\" category of the Amazon Review Data, and we will use the 5-core subset. You can download the dataset and find information about it here: https://nijianmo.github.io/amazon/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nSfoR_ux0C0B"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/ru-corporate/sandbox.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "URz4VUbL18A4"
      },
      "outputs": [],
      "source": [
        "# %mv /content/All_Beauty_5.json.gz ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZOknAhU4O-fV"
      },
      "outputs": [],
      "source": [
        "# !git status\n",
        "# !git add --all\n",
        "# !git commit -a -m \"Exercise lab session1\"\n",
        "# !git remote -v\n",
        "# !git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQIouQn00cX_"
      },
      "source": [
        "## Exercise 1\n",
        "Download and import the 5-core dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7aYOIAYW0wEI"
      },
      "outputs": [],
      "source": [
        "# !wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty_5.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5aD8CgLXJgSD"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "  # return pd.DataFrame.from_dict(df)\n",
        "\n",
        "\n",
        "# df = getDF('All_Beauty_5.json.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z4lSMEgDIpCY",
        "outputId": "395aed40-95f2-4299-de40-b3b14682c440"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Data:\n",
        "\n",
        "  def __init__(self,df):\n",
        "\n",
        "    self.df = df\n",
        "\n",
        "  def remove_duplicates(self):\n",
        "\n",
        "    df_clean = self.df[self.df['overall'].notna()]\n",
        "\n",
        "    df_clean = df_clean.sort_values(by =['reviewerID', 'asin', 'unixReviewTime'])\n",
        "    df_clean = df_clean.drop_duplicates(subset = ['reviewerID', 'asin', ], keep = 'last')\n",
        "    # df_clean.reset_index(level=0, inplace=True)\n",
        "    # self.clean_data(df_clean) # to call later \n",
        "    return df_clean.sort_values(by= ['reviewerID', 'unixReviewTime'])\n",
        "\n",
        "\n",
        "  def clean_data(self):\n",
        "        \n",
        "    df_clean = self.remove_duplicates()\n",
        "\n",
        "    positive_rating = df_clean[df_clean['overall'] >= 4.0]\n",
        "\n",
        "    # I was geting error typeerror unhashable type 'dict' over and over.\n",
        "    # Solution: make extra column with true index, so it won't be lost in \n",
        "    # the cleaning process\n",
        "\n",
        "    # positive_rating.reset_index(level=0, inplace=True)\n",
        "\n",
        "    #sort_it by unixReviewTime and keep most recent\n",
        "\n",
        "    # sorted = positive_rating.sort_values(by= ['reviewerID', 'unixReviewTime']).drop_duplicates(subset=['reviewerID'],keep= 'last')\n",
        "    sorted = positive_rating.drop_duplicates(subset=['reviewerID'],keep= 'last')\n",
        "\n",
        "  \n",
        "    return sorted\n",
        "\n",
        "\n",
        "  def get_train(self):\n",
        "\n",
        "    df_clean = self.remove_duplicates()\n",
        "\n",
        "    pre_test = self.clean_data()\n",
        "\n",
        "    train = df_clean[~df_clean.index.isin(pre_test.index)]\n",
        "\n",
        "    # self.get_test(train) # to call later \n",
        "    return train\n",
        "\n",
        "\n",
        "  def get_test(self):\n",
        "\n",
        "    # df_clean = self.remove_duplicates().set_index('index')\n",
        "    pre_test = self.clean_data()\n",
        "    train = self.get_train()\n",
        "    test = pre_test[pre_test.reviewerID.isin(train.reviewerID)]   \n",
        "    return test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "bebe = Data(df)\n",
        "\n",
        "pre_test = bebe.clean_data()\n",
        "\n",
        "train = bebe.get_train()\n",
        "\n",
        "test = bebe.get_test()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLgs68Fh0cYA"
      },
      "source": [
        "## Exercise 2\n",
        "Clean the dataset from missing ratings and duplicates (cases where the same user has rated the same item multiple times) if any. How many observations does the cleaned dataset have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LSm4Tu01I9V1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>07 6, 2014</td>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B0009RF9DW</td>\n",
              "      <td>{'Size:': ' 180'}</td>\n",
              "      <td>K. Mras</td>\n",
              "      <td>yum</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1404604800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>07 6, 2014</td>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B000FI4S1E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>K. Mras</td>\n",
              "      <td>yum</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1404604800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1976</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>07 6, 2014</td>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B000URXP6E</td>\n",
              "      <td>{'Size:': ' 180'}</td>\n",
              "      <td>K. Mras</td>\n",
              "      <td>yum</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1404604800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>07 6, 2014</td>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 180'}</td>\n",
              "      <td>K. Mras</td>\n",
              "      <td>yum</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1404604800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 13, 2013</td>\n",
              "      <td>A10JB7YPWZGRF4</td>\n",
              "      <td>B0009RF9DW</td>\n",
              "      <td>{'Size:': ' 45'}</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>I continually get compliments on how wonderful...</td>\n",
              "      <td>Heaven !</td>\n",
              "      <td>1376352000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4634</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 20, 2013</td>\n",
              "      <td>AZJMUP77WBQZQ</td>\n",
              "      <td>B001OHV1H4</td>\n",
              "      <td>{'Size:': ' 329'}</td>\n",
              "      <td>S. Foote</td>\n",
              "      <td>THIS WAS A GIFT PURCHASED LAST YEAR FOR MY DAU...</td>\n",
              "      <td>GIFT</td>\n",
              "      <td>1387497600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 28, 2014</td>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B0009RF9DW</td>\n",
              "      <td>{'Size:': ' 200'}</td>\n",
              "      <td>Norma Gandy</td>\n",
              "      <td>Like this product very much..it smells great.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1411862400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 28, 2014</td>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B000FI4S1E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Norma Gandy</td>\n",
              "      <td>Like this product very much..it smells great.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1411862400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 28, 2014</td>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B000URXP6E</td>\n",
              "      <td>{'Size:': ' 200'}</td>\n",
              "      <td>Norma Gandy</td>\n",
              "      <td>Like this product very much..it smells great.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1411862400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3848</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 28, 2014</td>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 200'}</td>\n",
              "      <td>Norma Gandy</td>\n",
              "      <td>Like this product very much..it smells great.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1411862400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4092 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      overall  verified   reviewTime      reviewerID        asin  \\\n",
              "737       5.0      True   07 6, 2014  A105A034ZG9EHO  B0009RF9DW   \n",
              "1120      5.0      True   07 6, 2014  A105A034ZG9EHO  B000FI4S1E   \n",
              "1976      5.0      True   07 6, 2014  A105A034ZG9EHO  B000URXP6E   \n",
              "3887      5.0      True   07 6, 2014  A105A034ZG9EHO  B0012Y0ZG2   \n",
              "809       5.0      True  08 13, 2013  A10JB7YPWZGRF4  B0009RF9DW   \n",
              "...       ...       ...          ...             ...         ...   \n",
              "4634      5.0      True  12 20, 2013   AZJMUP77WBQZQ  B001OHV1H4   \n",
              "719       5.0      True  09 28, 2014   AZRD4IZU6TBFV  B0009RF9DW   \n",
              "1102      5.0      True  09 28, 2014   AZRD4IZU6TBFV  B000FI4S1E   \n",
              "1936      5.0      True  09 28, 2014   AZRD4IZU6TBFV  B000URXP6E   \n",
              "3848      5.0      True  09 28, 2014   AZRD4IZU6TBFV  B0012Y0ZG2   \n",
              "\n",
              "                  style     reviewerName  \\\n",
              "737   {'Size:': ' 180'}          K. Mras   \n",
              "1120                NaN          K. Mras   \n",
              "1976  {'Size:': ' 180'}          K. Mras   \n",
              "3887  {'Size:': ' 180'}          K. Mras   \n",
              "809    {'Size:': ' 45'}  Amazon Customer   \n",
              "...                 ...              ...   \n",
              "4634  {'Size:': ' 329'}         S. Foote   \n",
              "719   {'Size:': ' 200'}      Norma Gandy   \n",
              "1102                NaN      Norma Gandy   \n",
              "1936  {'Size:': ' 200'}      Norma Gandy   \n",
              "3848  {'Size:': ' 200'}      Norma Gandy   \n",
              "\n",
              "                                             reviewText     summary  \\\n",
              "737                                                 yum  Five Stars   \n",
              "1120                                                yum  Five Stars   \n",
              "1976                                                yum  Five Stars   \n",
              "3887                                                yum  Five Stars   \n",
              "809   I continually get compliments on how wonderful...    Heaven !   \n",
              "...                                                 ...         ...   \n",
              "4634  THIS WAS A GIFT PURCHASED LAST YEAR FOR MY DAU...        GIFT   \n",
              "719       Like this product very much..it smells great.  Five Stars   \n",
              "1102      Like this product very much..it smells great.  Five Stars   \n",
              "1936      Like this product very much..it smells great.  Five Stars   \n",
              "3848      Like this product very much..it smells great.  Five Stars   \n",
              "\n",
              "      unixReviewTime vote image  \n",
              "737       1404604800  NaN   NaN  \n",
              "1120      1404604800  NaN   NaN  \n",
              "1976      1404604800  NaN   NaN  \n",
              "3887      1404604800  NaN   NaN  \n",
              "809       1376352000  NaN   NaN  \n",
              "...              ...  ...   ...  \n",
              "4634      1387497600  NaN   NaN  \n",
              "719       1411862400  NaN   NaN  \n",
              "1102      1411862400  NaN   NaN  \n",
              "1936      1411862400  NaN   NaN  \n",
              "3848      1411862400  NaN   NaN  \n",
              "\n",
              "[4092 rows x 12 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bebe.remove_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z89NNJ5c0cYB"
      },
      "source": [
        "## Exercise 3\n",
        "Create a test set by extracting the latest (in time) positively rated item (rating $\\geq 4$) by each user. Remove users that do not appear in the training set. How many observations does the training and test set have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy6zFzuIJAKZ",
        "outputId": "9462d89e-5f59-4c73-b718-a7041d2807ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length train set is :  3133\n",
            "length test set is :  949\n"
          ]
        }
      ],
      "source": [
        "print('length train set is : ', len(bebe.get_train())) \n",
        "print('length test set is : ', len(bebe.get_test())) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67CHfBZf0cYC"
      },
      "source": [
        "## Exercise 4\n",
        "### 4.1\n",
        "Compute the number of ratings per user in the training set. What is the summary statistics of the number of ratings, and how does a histogram look like? <br>\n",
        "Reflect on how a collaborative filtering and a content-based recommender system, respectively, will perform for users with few ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "_BwbGejR0cYD",
        "outputId": "6f063169-ec3c-4716-bc31-fcc72ed6bcc3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>981.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.193680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.610454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          overall\n",
              "count  981.000000\n",
              "mean     3.193680\n",
              "std      0.610454\n",
              "min      1.000000\n",
              "25%      3.000000\n",
              "50%      3.000000\n",
              "75%      3.000000\n",
              "max      9.000000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = bebe.get_train()\n",
        "\n",
        "def plot_dist(df,ff):\n",
        "\n",
        "  ba = df.groupby(ff).agg({'overall': 'count'}).reset_index().drop(ff, axis = 1)\n",
        "  plt.hist(ba['overall'], weights=np.ones(len(ba['overall'])) / len(ba['overall']), bins = range(11))\n",
        "  plt.xticks(range(10))\n",
        "  plt.title(f'Distribution rarings per {ff}')\n",
        "  plt.show()\n",
        "  return ba.describe()\n",
        "\n",
        "plot_dist(train,'reviewerID')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQb4D63N0cYD"
      },
      "source": [
        "### 4.2\n",
        "Compute the number of ratings per item in the training set. How does a barplot of the number of ratings ordered by decreasing frequency look like? <br>\n",
        "Reflect on how it will affect the prediction process of a recommender system if only a small fraction of the items are rated frequently. <br>\n",
        "<br>\n",
        "Repeat this exercise on the test set and reflect on how the evaluation of a recommender system can be affected by popular items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wKN8pBW20cYD",
        "outputId": "da7287d6-566e-4806-c2cf-6da9d18be856"
      },
      "outputs": [],
      "source": [
        "def ex4_2(train):\n",
        "    s = pd.Series(train['asin'].value_counts(), name='counts')\n",
        "\n",
        "    tr = (s.to_frame())\n",
        "    # tr = tr.sort_values(by = ['counts'], ascending= False)\n",
        "\n",
        "\n",
        "    #new column for ranking. to make a axis\n",
        "    tr['index'] = tr.rank(ascending=False, method='first')\n",
        "\n",
        "    # tr\n",
        "    tr['counts'].plot(kind = 'bar', xticks=tr['index'] )\n",
        "    plt.xticks(range(70))\n",
        "\n",
        "    plt.show();\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ex4_2(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGhCAYAAACphlRxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1EElEQVR4nO3de3RU5b3/8c/O/UISSEIyiYSQVhAxoDZwkFQF5JrK3YoWLXCKWsulzQJqC/5asaUJxcrlgM2pHioKIvZUwbbcxFJADsUDtLSAVWkFDSUxipgQiBMM398fruzDkIQact3h/Vprr5WZ77P3fvbkycwne/Y845iZCQAAwCOCWroDAAAA9UF4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnhLS0h24HOfPn9eJEycUExMjx3FaujsAAOBzMDOdPn1aqampCgq6/PMnngwvJ06cUFpaWkt3AwAAXIbCwkJ16tTpstf3ZHiJiYmR9NnBx8bGtnBvAADA51FWVqa0tDT3dfxyeTK8VL9VFBsbS3gBAMBjGnrJBxfsAgAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATyG8AAAATwlp6Q40VJfvbwi4fWzB7S3UEwAA0Bw48wIAADyF8AIAADylXuGloKBAvXr1UmxsrGJjY9WvXz9t2rTJrU+ePFmO4wQsN910U8A2/H6/ZsyYocTEREVHR2vUqFE6fvx44xwNAABo8+oVXjp16qQFCxZo37592rdvn2677TaNHj1ahw8fdtsMHz5cRUVF7rJx48aAbeTm5mrdunVau3atdu3apfLyco0YMUJVVVWNc0QAAKBNq9cFuyNHjgy4/ZOf/EQFBQXas2ePrrvuOklSeHi4fD5freuXlpZqxYoVWrVqlQYPHixJWr16tdLS0vTqq69q2LBhl3MMAADgCnLZ17xUVVVp7dq1OnPmjPr16+fev337diUlJalbt266//77VVJS4tb279+vc+fOaejQoe59qampyszM1O7du+vcl9/vV1lZWcACAACuTPUOLwcPHlS7du0UHh6uBx98UOvWrVOPHj0kSTk5OXruuee0bds2Pf7449q7d69uu+02+f1+SVJxcbHCwsLUoUOHgG0mJyeruLi4zn3m5+crLi7OXdLS0urbbQAA0EbUe56Xa665RgcOHNDHH3+sF198UZMmTdKOHTvUo0cP3XXXXW67zMxM9e7dW+np6dqwYYPGjRtX5zbNTI7j1FmfM2eOZs6c6d4uKysjwAAAcIWqd3gJCwvT1VdfLUnq3bu39u7dq6VLl+oXv/hFjbYpKSlKT0/XkSNHJEk+n0+VlZU6depUwNmXkpISZWdn17nP8PBwhYeH17erAACgDWrwPC9m5r4tdLGTJ0+qsLBQKSkpkqSsrCyFhoZq69atbpuioiIdOnTokuEFAACgWr3OvMydO1c5OTlKS0vT6dOntXbtWm3fvl2bN29WeXm55s2bpzvuuEMpKSk6duyY5s6dq8TERI0dO1aSFBcXpylTpmjWrFlKSEhQfHy8Zs+erZ49e7qfPgIAALiUeoWX999/X1//+tdVVFSkuLg49erVS5s3b9aQIUNUUVGhgwcP6tlnn9XHH3+slJQUDRw4UC+88IJiYmLcbSxevFghISEaP368KioqNGjQIK1cuVLBwcGNfnAAAKDtcczMWroT9VVWVqa4uDiVlpaqV95rATW+mBEAgNbpwtfv2NjYy96O579V+lL4xmkAANoevpgRAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4Sr3CS0FBgXr16qXY2FjFxsaqX79+2rRpk1s3M82bN0+pqamKjIzUgAEDdPjw4YBt+P1+zZgxQ4mJiYqOjtaoUaN0/PjxxjkaAADQ5tUrvHTq1EkLFizQvn37tG/fPt12220aPXq0G1AWLlyoRYsWafny5dq7d698Pp+GDBmi06dPu9vIzc3VunXrtHbtWu3atUvl5eUaMWKEqqqqGvfIAABAm1Sv8DJy5Eh95StfUbdu3dStWzf95Cc/Ubt27bRnzx6ZmZYsWaKHH35Y48aNU2Zmpp555hmdPXtWa9askSSVlpZqxYoVevzxxzV48GDdeOONWr16tQ4ePKhXX321SQ4QAAC0LZd9zUtVVZXWrl2rM2fOqF+/fjp69KiKi4s1dOhQt014eLj69++v3bt3S5L279+vc+fOBbRJTU1VZmam2wYAAOBSQuq7wsGDB9WvXz998sknateundatW6cePXq44SM5OTmgfXJyst59911JUnFxscLCwtShQ4cabYqLi+vcp9/vl9/vd2+XlZXVt9sAAKCNqPeZl2uuuUYHDhzQnj179K1vfUuTJk3SG2+84dYdxwlob2Y17rvYv2qTn5+vuLg4d0lLS6tvtwEAQBtR7/ASFhamq6++Wr1791Z+fr6uv/56LV26VD6fT5JqnEEpKSlxz8b4fD5VVlbq1KlTdbapzZw5c1RaWuouhYWF9e02AABoIxo8z4uZye/3KyMjQz6fT1u3bnVrlZWV2rFjh7KzsyVJWVlZCg0NDWhTVFSkQ4cOuW1qEx4e7n48u3oBAABXpnpd8zJ37lzl5OQoLS1Np0+f1tq1a7V9+3Zt3rxZjuMoNzdXeXl56tq1q7p27aq8vDxFRUVpwoQJkqS4uDhNmTJFs2bNUkJCguLj4zV79mz17NlTgwcPbpIDBAAAbUu9wsv777+vr3/96yoqKlJcXJx69eqlzZs3a8iQIZKkhx56SBUVFZo6dapOnTqlvn376pVXXlFMTIy7jcWLFyskJETjx49XRUWFBg0apJUrVyo4OLhxjwwAALRJjplZS3eivsrKyhQXF6fS0lL1ynstoHZswe3uz12+v6HOGgAAaF4Xvn435BIQvtsIAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4Sr3CS35+vvr06aOYmBglJSVpzJgxeuuttwLaTJ48WY7jBCw33XRTQBu/368ZM2YoMTFR0dHRGjVqlI4fP97wowEAAG1evcLLjh07NG3aNO3Zs0dbt27Vp59+qqFDh+rMmTMB7YYPH66ioiJ32bhxY0A9NzdX69at09q1a7Vr1y6Vl5drxIgRqqqqavgRAQCANi2kPo03b94ccPvpp59WUlKS9u/fr1tvvdW9Pzw8XD6fr9ZtlJaWasWKFVq1apUGDx4sSVq9erXS0tL06quvatiwYfU9BgAAcAVp0DUvpaWlkqT4+PiA+7dv366kpCR169ZN999/v0pKStza/v37de7cOQ0dOtS9LzU1VZmZmdq9e3dDugMAAK4A9TrzciEz08yZM3XzzTcrMzPTvT8nJ0d33nmn0tPTdfToUf3gBz/Qbbfdpv379ys8PFzFxcUKCwtThw4dAraXnJys4uLiWvfl9/vl9/vd22VlZZfbbQAA4HGXHV6mT5+uv/71r9q1a1fA/XfddZf7c2Zmpnr37q309HRt2LBB48aNq3N7ZibHcWqt5efn69FHH73crgIAgDbkst42mjFjhn7zm9/oD3/4gzp16nTJtikpKUpPT9eRI0ckST6fT5WVlTp16lRAu5KSEiUnJ9e6jTlz5qi0tNRdCgsLL6fbAACgDahXeDEzTZ8+XS+99JK2bdumjIyMf7nOyZMnVVhYqJSUFElSVlaWQkNDtXXrVrdNUVGRDh06pOzs7Fq3ER4ertjY2IAFAABcmer1ttG0adO0Zs0avfzyy4qJiXGvUYmLi1NkZKTKy8s1b9483XHHHUpJSdGxY8c0d+5cJSYmauzYsW7bKVOmaNasWUpISFB8fLxmz56tnj17up8+AgAAqEu9wktBQYEkacCAAQH3P/3005o8ebKCg4N18OBBPfvss/r444+VkpKigQMH6oUXXlBMTIzbfvHixQoJCdH48eNVUVGhQYMGaeXKlQoODm74EQEAgDatXuHFzC5Zj4yM1JYtW/7ldiIiIrRs2TItW7asPrsHAADgu40AAIC3EF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICnEF4AAICn1Cu85Ofnq0+fPoqJiVFSUpLGjBmjt956K6CNmWnevHlKTU1VZGSkBgwYoMOHDwe08fv9mjFjhhITExUdHa1Ro0bp+PHjDT8aAADQ5tUrvOzYsUPTpk3Tnj17tHXrVn366acaOnSozpw547ZZuHChFi1apOXLl2vv3r3y+XwaMmSITp8+7bbJzc3VunXrtHbtWu3atUvl5eUaMWKEqqqqGu/IAABAmxRSn8abN28OuP30008rKSlJ+/fv16233ioz05IlS/Twww9r3LhxkqRnnnlGycnJWrNmjb75zW+qtLRUK1as0KpVqzR48GBJ0urVq5WWlqZXX31Vw4YNa6RDAwAAbVGDrnkpLS2VJMXHx0uSjh49quLiYg0dOtRtEx4erv79+2v37t2SpP379+vcuXMBbVJTU5WZmem2AQAAqEu9zrxcyMw0c+ZM3XzzzcrMzJQkFRcXS5KSk5MD2iYnJ+vdd99124SFhalDhw412lSvfzG/3y+/3+/eLisru9xuAwAAj7vsMy/Tp0/XX//6Vz3//PM1ao7jBNw2sxr3XexSbfLz8xUXF+cuaWlpl9ttAADgcZcVXmbMmKHf/OY3+sMf/qBOnTq59/t8PkmqcQalpKTEPRvj8/lUWVmpU6dO1dnmYnPmzFFpaam7FBYWXk63AQBAG1Cv8GJmmj59ul566SVt27ZNGRkZAfWMjAz5fD5t3brVva+yslI7duxQdna2JCkrK0uhoaEBbYqKinTo0CG3zcXCw8MVGxsbsAAAgCtTva55mTZtmtasWaOXX35ZMTEx7hmWuLg4RUZGynEc5ebmKi8vT127dlXXrl2Vl5enqKgoTZgwwW07ZcoUzZo1SwkJCYqPj9fs2bPVs2dP99NHAAAAdalXeCkoKJAkDRgwIOD+p59+WpMnT5YkPfTQQ6qoqNDUqVN16tQp9e3bV6+88opiYmLc9osXL1ZISIjGjx+viooKDRo0SCtXrlRwcHDDjgYAALR5jplZS3eivsrKyhQXF6fS0lL1ynstoHZswe3uz12+v6HOGgAAaF4Xvn435BIQvtsIAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4CuEFAAB4Sr3Dy86dOzVy5EilpqbKcRytX78+oD558mQ5jhOw3HTTTQFt/H6/ZsyYocTEREVHR2vUqFE6fvx4gw4EAABcGeodXs6cOaPrr79ey5cvr7PN8OHDVVRU5C4bN24MqOfm5mrdunVau3atdu3apfLyco0YMUJVVVX1PwIAAHBFCanvCjk5OcrJyblkm/DwcPl8vlprpaWlWrFihVatWqXBgwdLklavXq20tDS9+uqrGjZsWH27BAAAriBNcs3L9u3blZSUpG7duun+++9XSUmJW9u/f7/OnTunoUOHuvelpqYqMzNTu3fvrnV7fr9fZWVlAQsAALgyNXp4ycnJ0XPPPadt27bp8ccf1969e3XbbbfJ7/dLkoqLixUWFqYOHToErJecnKzi4uJat5mfn6+4uDh3SUtLa+xuAwAAj6j320b/yl133eX+nJmZqd69eys9PV0bNmzQuHHj6lzPzOQ4Tq21OXPmaObMme7tsrIyAgwAAFeoJv+odEpKitLT03XkyBFJks/nU2VlpU6dOhXQrqSkRMnJybVuIzw8XLGxsQELAAC4MjV5eDl58qQKCwuVkpIiScrKylJoaKi2bt3qtikqKtKhQ4eUnZ3d1N0BAAAeV++3jcrLy/X3v//dvX306FEdOHBA8fHxio+P17x583THHXcoJSVFx44d09y5c5WYmKixY8dKkuLi4jRlyhTNmjVLCQkJio+P1+zZs9WzZ0/300cAAAB1qXd42bdvnwYOHOjerr4WZdKkSSooKNDBgwf17LPP6uOPP1ZKSooGDhyoF154QTExMe46ixcvVkhIiMaPH6+KigoNGjRIK1euVHBwcCMcEgAAaMvqHV4GDBggM6uzvmXLln+5jYiICC1btkzLli2r7+4BAMAVju82AgAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnkJ4AQAAnlLv8LJz506NHDlSqampchxH69evD6ibmebNm6fU1FRFRkZqwIABOnz4cEAbv9+vGTNmKDExUdHR0Ro1apSOHz/eoAMBAABXhnqHlzNnzuj666/X8uXLa60vXLhQixYt0vLly7V37175fD4NGTJEp0+fdtvk5uZq3bp1Wrt2rXbt2qXy8nKNGDFCVVVVl38kAADgihBS3xVycnKUk5NTa83MtGTJEj388MMaN26cJOmZZ55RcnKy1qxZo29+85sqLS3VihUrtGrVKg0ePFiStHr1aqWlpenVV1/VsGHDGnA4AACgrWvUa16OHj2q4uJiDR061L0vPDxc/fv31+7duyVJ+/fv17lz5wLapKamKjMz021zMb/fr7KysoAFAABcmRo1vBQXF0uSkpOTA+5PTk52a8XFxQoLC1OHDh3qbHOx/Px8xcXFuUtaWlpjdhsAAHhIk3zayHGcgNtmVuO+i12qzZw5c1RaWuouhYWFjdZXAADgLY0aXnw+nyTVOINSUlLino3x+XyqrKzUqVOn6mxzsfDwcMXGxgYsAADgytSo4SUjI0M+n09bt25176usrNSOHTuUnZ0tScrKylJoaGhAm6KiIh06dMhtAwAAUJd6f9qovLxcf//7393bR48e1YEDBxQfH6/OnTsrNzdXeXl56tq1q7p27aq8vDxFRUVpwoQJkqS4uDhNmTJFs2bNUkJCguLj4zV79mz17NnT/fQRAABAXeodXvbt26eBAwe6t2fOnClJmjRpklauXKmHHnpIFRUVmjp1qk6dOqW+ffvqlVdeUUxMjLvO4sWLFRISovHjx6uiokKDBg3SypUrFRwc3AiHBAAA2jLHzKylO1FfZWVliouLU2lpqXrlvRZQO7bgdvfnLt/fUGcNAAA0rwtfvxty/SrfbQQAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyF8AIAADyl0cPLvHnz5DhOwOLz+dy6mWnevHlKTU1VZGSkBgwYoMOHDzd2NwAAQBvVJGderrvuOhUVFbnLwYMH3drChQu1aNEiLV++XHv37pXP59OQIUN0+vTppugKAABoY5okvISEhMjn87lLx44dJX121mXJkiV6+OGHNW7cOGVmZuqZZ57R2bNntWbNmqboCgAAaGOaJLwcOXJEqampysjI0N1336133nlHknT06FEVFxdr6NChbtvw8HD1799fu3fvrnN7fr9fZWVlAQsAALgyNXp46du3r5599llt2bJFTz31lIqLi5Wdna2TJ0+quLhYkpScnBywTnJyslurTX5+vuLi4twlLS2tsbsNAAA8otHDS05Oju644w717NlTgwcP1oYNGyRJzzzzjNvGcZyAdcysxn0XmjNnjkpLS92lsLCwsbsNAAA8osk/Kh0dHa2ePXvqyJEj7qeOLj7LUlJSUuNszIXCw8MVGxsbsAAAgCtTk4cXv9+vv/3tb0pJSVFGRoZ8Pp+2bt3q1isrK7Vjxw5lZ2c3dVcAAEAbENLYG5w9e7ZGjhypzp07q6SkRPPnz1dZWZkmTZokx3GUm5urvLw8de3aVV27dlVeXp6ioqI0YcKExu4KAABogxo9vBw/flxf+9rX9OGHH6pjx4666aabtGfPHqWnp0uSHnroIVVUVGjq1Kk6deqU+vbtq1deeUUxMTGN3RUAANAGNXp4Wbt27SXrjuNo3rx5mjdvXmPvGgAAXAH4biMAAOAphBcAAOAphBcAAOAphBcAAOAphBcAAOAphBcAAOAphBcAAOAphBcAAOAphBcAAOApjT7Drld0+f6GgNvHFtzeQj0BAAD1wZkXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKYQXAADgKVfs1wP8Kxd+fQBfHQAAQOvBmRcAAOApnHm5DJyVAQCg5XDmBQAAeArhBQAAeArhBQAAeArhBQAAeArhBQAAeArhBQAAeArhBQAAeArhBQAAeAqT1DUyJrADAKBpceYFAAB4CmdemtGFZ2WkwDMzl6oBAID/Q3jxAIINAAD/h/DicZzNAQBcaQgvV7BLXVx8uTUAAJoa4QWN6nLPBHEGCQDwebVoePn5z3+uxx57TEVFRbruuuu0ZMkS3XLLLS3ZJXhQU5xBIoQBQOvVYh+VfuGFF5Sbm6uHH35Yf/7zn3XLLbcoJydH7733Xkt1CWhRXb6/wV0AAHVrsTMvixYt0pQpU3TfffdJkpYsWaItW7aooKBA+fn5LdUtoFXiGiQA+D8tEl4qKyu1f/9+ff/73w+4f+jQodq9e3dLdAlok3j7C0Bb1CLh5cMPP1RVVZWSk5MD7k9OTlZxcXGN9n6/X36/371dWloqSSorK9N5/9mAtmVlZe7Pl1u7uN4Utcbq65V+jI3VV46j8Y4j85Et7s+HHh3WrLWL601Ra6y+tobjAJpb9fOFmTVsQ9YC/vnPf5ok2717d8D98+fPt2uuuaZG+0ceecQksbCwsLCwsLSB5R//+EeDckSLnHlJTExUcHBwjbMsJSUlNc7GSNKcOXM0c+ZM9/b58+f10UcfKSEhQY7jqKysTGlpaSosLFRsbGzAus1da4l9chxt/ziuhGNsbf250o/jSjjG1tafK+E4SktL1blzZ8XHx9c4hvpokfASFhamrKwsbd26VWPHjnXv37p1q0aPHl2jfXh4uMLDwwPua9++fY12sbGxtf5SW6LW2vrDcbSu/nCMHEdbqLW2/nAcras/l6oFBTXsw84t9mmjmTNn6utf/7p69+6tfv366cknn9R7772nBx98sKW6BAAAPKDFwstdd92lkydP6kc/+pGKioqUmZmpjRs3Kj09vaW6BAAAPKBFZ9idOnWqpk6d2uDthIeH65FHHqnx1lJL1FpbfziO1tUfjpHjaAu11tYfjqN19achx/F5OWYN/bwSAABA82mxrwcAAAC4HIQXAADgKYQXAADgKYSXy8SlQgAAtIwW/bTR5Tp+/LgKCgq0e/duFRcXy3EcJScnKzs7Ww8++KDS0tKavA/h4eH6y1/+omuvvbbJ93WxoqIiFRQUaNeuXSoqKlJwcLAyMjI0ZswYTZ48WcHBwc3eJwAAmovnPm20a9cu5eTkKC0tTUOHDlVycrLMTCUlJdq6dasKCwu1adMmffnLX66xbkVFhTZu3KjnnntOL730UkDtwIEDWr58uWbPnq3u3bvrzTff1NKlS/Xaa6+pe/fu6ty5c0D7pUuX6t5771VCQoIkadGiRZKkU6dO6ZlnntGRI0dkZrrnnnvcvqxevVoFBQV67733VFVVpQceeEDz5s2r9TiXLVumffv26fbbb9f48eO1atUq5efn6+zZsyouLlb37t0VFRWl119/Xffcc48qKyu1ZcsWXXvttdqyZYtiYmIa+lC3SWfOnNGaNWtqBN8vf/nL+trXvqbo6Oha13v//fe1cOFCPfroo2rXrl1Arbi4WGvXrtXEiRMVHx+vDz/8UCtWrJDf79edd95ZI+B+4Qtf0JYtW9S1a1f3vnPnzmnDhg06cuSIwsPDNXr0aHfOo9dee03/+Z//qffee0/p6enq0KGDZs+eXeecSL/97W+1b98+DR8+XP369dO2bdv0s5/9TOfPn9eIESMUFRVVa/AdNGhQQx7aNq01jBupYWPn7NmzevjhhzVu3Lha+8q4aRpNMXbOnTunzZs3q127drr++uub/HmnVY6dBn0zUgvo3bu35ebm1lnPzc213r1717j/rbfesvT0dHMcxyRZ//797cSJE2ZmtmnTJgsLCzNJFhERYZs2bbKOHTva4MGD3S+Ruv76623AgAHu4jiO9enTx8LCwuzmm282M7N33nnHfD6f+Xw+GzJkiIWGhlp0dLT97W9/s6eeesoiIyPt29/+thUUFLjbTU5OtgULFlhRUZHb1x/96EcWExNjd9xxh/l8PluwYIElJCTY/PnzLT093aKiouyHP/yhmZmtWrXK+vbta2ZmH330kd1www32rW99y5588kmbPHmyDR8+3HJycmzy5Mn21FNPWXl5eZ2PXXFxsc2cOdNOnz5do1ZUVGSLFy+2kydPmpnZBx98YAsWLLBHH33U3njjjRrtMzIy7O23365xf2Vlpa1bt84WLlxoS5cutWPHjrm1nTt32oQJE+zmm2+2L33pS/biiy/W2dff/OY39sMf/tD9cs/f//73lpOTY8OGDbNly5bZihUr7N///d9t+PDhdvvtt9v06dNtxYoVlpqaau3bt7fRo0fbAw88YPfff7+NHj3a2rdvb1dddZUdPny4xr5OnDhh1113nUmy4OBgmzhxovsYvf766xYbG2uSrEOHDrZv3z7LyMiwrl27WmJiooWGhtrs2bNt6dKl7hIcHGxXXXWV5efn29KlS62kpMR69uxpYWFh1rVrV3Mcxzp27GjHjx+39evXW1BQkI0aNcq+973v2dixY02SBQUF2eDBg23t2rXm9/vdvhYUFFhISIhlZWVZbGysrV692mJiYuy+++6zu+++2xzHsejoaEtJSTHHcez222+3vn37WnBwsI0dO9YKCgpadNyY1T52rqRxc/XVV9c6bho6dqqfc2644YZGHTd33nmnffzxx63yOefCcbNq1Sp766237IMPPvD02DEz27hxo0kyx3Ga5XmnKcfOuXPn6nzML8Vz4SUiIsLefPPNOutPPPGEhYaG2ssvvxyw9O3b1/r06WM//vGPzXEcGzlypGVkZNi7775r/fr1s9zcXAsKCrLnn3/eOnToYHPnzjUzs7y8PGvfvr1lZWUF7CckJMQOHz5sjuPY+++/b2Zmd999tw0YMMDOnDljZmZRUVE2aNAg++pXv2o33nij/eIXv3DXdxzH5syZY/Hx8e5gGzVqlP32t7+1L3zhC+4f0YEDByw4ONhWr15tZmaRkZH285//3K6++mozM6uqqrLQ0FArLi42M7OnnnrKgoKCWsUL9Jw5c6xLly6Wn59vZtbifyySLC0tzf39XGjfvn02fPhw6927t/3lL38JWEaOHOn2d+vWrda7d2/Lysqyjz76yAYPHmz33HOPSbLHHnvMOnXqZPfdd5/7O46OjraoqCjr0qWLu1QH6LS0NMvIyLD777/fbrjhBjfAtmvXzr70pS/ZN77xDevbt68tWLAgoK+O41jnzp1t9OjRFhoaagkJCfad73zHDh48aNdee609+eSTZma2bds2i4iIsCeeeMLMzHJycmzAgAHWvXt3MzPLz8+3nJwcM/vsyTA4ONgiIiJ4gW7hcWNmJskiIyMDxk1Dx47jOHbPPfdYXFxco42bt99+21JTUy0mJqZVPOdcatxERERYWFiYPfvss2Zmnh07Zma33nqrSbKysrJmed5pqrHTpUsXe+SRR2o8Np+H58JLRkaG/fKXv6yzXv0LchwnYKkemI7jWFBQkJmZTZ061Tp37mzt2rWzP/7xjxYUFGRVVVUWEhJi+/fvd7f5/PPPW3BwsM2aNcsqKyvNrPbwkpGRYb///e/d9RISEmzlypXWqVMnS0pKsgMHDgT08/XXX7fIyEirrKy0F154wYYNG2bBwcHmOI5NmzbNjhw5YmZmoaGhdujQITMzS09Pt1//+tcWFRVlZp89ATiOY2fPnjUzs5tuusmCgoIC/vCqNfcL9FVXXWWSrHPnzmZmLf7HEhERYampqbX+sVSPi0uNnepx88knn9jo0aPthhtusPbt29vOnTstKCjIKisrLSgoyF5//XUzM3vggQfsmmuusaSkpIB9hYSEBIybbt262e9+9zu3HhcXZ//1X/9lXbp0saSkJPvLX/5So6+RkZFmZvb+++/bT3/6U+vevbsFBQVZUFCQ5efnW1lZmTt2Dh48aGafhelt27a5Y8fv91toaKh9+OGHNmDAALvlllssPT29WcaNmXdeoJt73JiZjRs3zkJDQ2ucYWjI2Kl+zomKimq0cWNmlpmZadHR0a3iOedS4+bDDz90/9s3M8+OnZMnT1r79u3NcRwzs2Z53mmqsbN+/Xrr0qVLjcfm8/BceHniiScsLCzMpk2bZuvXr7c//vGPtmfPHlu/fr1NmzbNJNk3v/nNGuvFxMTYG2+8YX/+85/dAWFmNn36dHMcx9asWePe365dO/vHP/7htjl27JiFh4fbxIkTrWfPnvbXv/7VQkND3fBSUlJiZmapqaluyDAzu/fee238+PEWHh5ud955p/2///f/3JrjODZ37lzr2bNnQD/fffdda9++vSUlJVlQUJC9/fbbFhQUZL/61a/MzOw73/mOpaenW1JSkm3bts0GDhxoAwYMcNcPDw+3tLS0Wh+75n6BvjjctfQfS2pqqns26GKJiYk2bdo0S0pKsmPHjgUsUVFR9uSTTwaMm3PnztmYMWMsKCjINm3aVOfYefLJJ02SLVu2LOCxuXDcJCUlBfxnOmrUKPvWt75l4eHhNmzYMFu6dGmN32NGRkaNY9i5c6dFRUVZRESERUdH2z//+U9zHMc2bNhgZp+NzyeffNI6depkZmanTp0yx3GsrKzMIiMjbcuWLRYeHl5ju1f6C3RLjJt3333XQkNDLS0trdHGjuM49vjjj1vXrl0DjqEh48bssxfo0NDQGo9N9T5byz8FZmbR0dGWmprqPnZeHDu9evWyyMhIN7yYNf3zTlONnXfeeafW55zPw3Phxcxs7dq11rdvX/eX4TiOhYSEWN++fS0rK8t+8IMf1FinT58+9uyzz9qBAwcCfulmn50hiY6OdgfKwYMHA96He+2119wXi+eff96Sk5MtKCjIfXHu2bOn3XjjjdauXTt76aWX3PX++c9/ms/ns7CwMJs5c6ZFRkbazTffbPfff79JstDQUPeXfKGHH37YOnbsaDk5OZaRkWFz5syxzp07W0FBgS1ZssQiIyMtKCjIHMex7Oxse+eddwKO5bvf/W6tj1tzv0BfHO5a+o/lkUcesZiYGAsODrYDBw5YUVGRFRcX24EDB6xbt24WERFhjz76aI3HrWfPnvazn/2sxrg5d+6ctWvXzg2aZma/+93v3LNgZmZ79uyxlJQUu+2222z48OFWVFTkjtuvfOUrNnbsWOvQoYNt3LjRXeeNN96wuLg4i4iIsB//+MfWrl07u/fee+0nP/mJTZw40STVCDTVpk2bZl/84hdt9OjR9m//9m82adIk6969u23atMkGDx5s0dHRNm7cOHvnnXfsrrvushtvvNF93ObPn19r8L3SX6Bbatx06tTJjh8/3mhjx3EcCwsLs6effrpGXy933FSPj8TExBrbrK61ln8KzMwGDx5swcHBZmaeHTtjxoxxj7VaUz/vNNXY2b59e53/bP8rngwv1SorK+3EiRN24sQJ9+2cnTt32qZNm2q0zcvLs5ycHCsvL7ft27cH1AoKCuwrX/lKjYFSbe7cuTZlyhT3dmFhoa1fv97Ky8tt3rx5AcvmzZsD1p0+fbpde+211qNHD/c91/T0dIuOjratW7fWur9PP/3U5s+fbyNGjHBPaz7//POWlpZmCQkJNnnyZPvwww9rvcjtkUcesbi4OHvsscda/AW6Ory0pj+WBx54wA1+1f9ROc5nF73dddddtf4+HnroIRs4cKCtXLmyRu2HP/yhZWVlBTwBX2ju3Lk2btw4O3/+vOXl5ZnP57Pg4GAbM2aMTZ482V2qz6xVu++++8zn81lMTIwb0ENDQy07Ozvgv8uLlZeX23333WeZmZn24IMPWmVlpT322GPuBemxsbHusXfp0sX+9Kc/mdln4yYqKspGjx7NC3QrGjdm1mhjR1Ktj4vZ5Y8bM7M777zTIiMjW8VzzqXGjdlnz6OO49jEiRM9O3bOnTtn11xzTZ2vV2aN/7zTVGPnv//7v+0//uM/6jyOS/F0eEHtFixY4F441phPtJcKd7X9oRw+fDjgD6U1/bG88847tnv3btu9e3fAmavanDt3zkpLS+usf/rppwGffrnQmTNn7JNPPnFv79u3z5YsWeJeeFeX8vJyq6iosPPnz1txcXFAQL8cFRUV7qnat99+u8bZRbOmGzdt4QW6tnFz4ZmAi50/f77OcXP+/Hkzq33cVNcuHjdmn42dRYsW1Tl2qtetbezUdj3KxevV5syZM3WOmwvXa6mxU99xM3v2bLvlllvs7rvvbtKxc+E1k839nGPWOp53Ps9zTkN4bp4XfH5Hjx5VcXGxJMnn8ykjI6POtp9++qnOnj2r2NjYWutVVVU6fvx4rXOLnD17VsHBwe5XnO/fv1+7du3SxIkT1aFDh0v28cyZM+66JSUlOn/+vBITExUaGvp5D9P1ySef6Ny5c4qJidGRI0fk9/vVvXt3hYR4ci7GFtNS40b6/GOnNYybsLCwOieqbIpaS+yzvrWWGjt/+tOf9Nprr33ucRMREeHOD8ZzjjfxCLdhGRkZNZ48CgsL9cgjj+iXv/xlwP0hISEqLS1Vbm5ujZoknThxQo8++mittZMnTwZsMysrS1lZWZfcX7WPPvrIrScnJ3+uvtZVi4iIUEREhAoLC5Wfn1/rekeOHFFubq4ee+wx9ejRI6B26tQpPf7445owYUKrrn3yySdavXq1unfvrvj4+EbbbvVEjd/97nfVr18/vfnmm1q4cKH8fr9uueUWSVK/fv0CJnFsSO3ee+9VSkqK9uzZ49ajo6P15ptvatasWe662dnZuuaaa2rd7oW1H/3oR5+7P/9qmyEhIf9yosqqqirdcccdioyMlCT179+/UWoLFizQoUOHatSacp8N6euFE3VmZGSoffv27kSdqampmjhxojvr+YWTeKakpGjSpElueLm4NnnyZDe41LbehdvcuXOnjhw5oieeeKJGra71HMdRWFhYvfpaWy01NVWTJk1yJ3/7vBOVJiQk6Bvf+Ia+/e1v16uWnp6u22+/XXfffbf7/N4Y223uWnp6uqZPn667775bl6XRzuHAEw4cOFDnqdjmrjX3Pt966y1LSUlxP+Fw4USFb731lnXq1KnV18zM/ud//ifgY/+Nsd1LTdR4ww03mCSLiYlptNqgQYMsKCjIQkNDLT4+vln2ebk1XWKiSknWrl07a9++faPV+vTp49YvrDXlPhvS14sn6kxJSXEn6gwKCrKYmBj729/+VmMSz+auderUyRzHcSeZa459Xmqi0o4dO1pERIStWLGiXrXqOcmqP5jRWNtt7lpubq61a9fOVqxYUevz+L9CeGljLp6c78Kl+sJjx3Gapfbyyy9fstbc/enbt6/16NHDHMexI0eOBExUOGbMGBsyZEirr5l9Nq+EJPvggw8abbuXmqixX79+lp2dbUOGDGm0mpnZVVddFfApvqbe5+XWLjVRZW5ubo35nRpaO3z4sOXl5TX6dpuqrxdeQH7xRJ2O49iQIUPsq1/9aovXPvnkE5NkI0aMaLa+Xmqi0qioKFu6dKn16NGjXjWzz6bEqP5UVGNtt7lrZmbPPfec9ejRwy4H4aWNqf5v/OI5FS6cV6H6v/amrl1Ybw39qb7/wrMy1RMVJiQk2B/+8IdWX/vHP/5hiYmJNS6ebuh2LzVRY2xsrG3YsMGSk5MbrWb22cdfExISzMyaZZ8N6eulJqr83//9X+vWrVuj1sysSbbbFLULw8vFIcdxHNu4caN16tSpxWvV9ZSUlGbr66UmKk1ISLD169dbZGRkvWpmZh06dHDnR2ms7TZ3zczs73//uzvhZn0FXd6bTWitUlJS9OKLL+r8+fM1ltTUVC1atEhBQUHNUjt//rw6duwox3FaRX9iYmL04osvBjxeTzzxhEaNGqWPPvpIhYWFrb7Wv39/nT17tsbvvaHbPXPmjI4ePSpJCgoKUkREhNq3b++2i46OVmlpaaPWHMfR6dOnm3Wfl1vr16+fQkJC9MEHHygrK0sHDx6U4ziSpD59+mj//v2NWmuq7TZVX6t/9vv9Na5dS0pK0gcffNAqatJn1+g1V19zcnK0ceNGffDBB+rfv79+/etfB9Tmz5+vq6++ul41SUpPT1dUVJQkNdp2m7smSb/61a909dVX67JcVuRBqzVy5MhaJ+mrrj3wwAO1fuS5KWpmZv3797e6hllz96dPnz42f/78WmtJSUkWFRVV67Uyrak2bdo09yskanO5273URI29evWyn/3sZ+5bPI1RMzP74he/aMnJye7tpt5nQ/p6qYkqL9QUtZbYZ31qjlP3RJ2O49gXvvAFCw0NbfFadT0kJKTZ+nqpiUqrv/soMzOzXrVbb73VQkNDLTk52W699dZG225z12699VYLCwurdaLWz4Pw0sbUNUlfdW3dunU1JulrqpqZ2ZYtW+ynP/1pq+hPXl6eDR06tM5a586daw0FralmZu4TQm0ud7uXmqixoKDAxo8fHzBRY0NrZmbDhw+3IUOG1Fprin02pK+XmqjyYk1Ra4l9ft7apSbqnDdvnmVnZ1tmZmaL18wsoNZc+6xrotIJEybYtm3b7Hvf+169a3v37rVTp05d1rqtqbZ3794aY+vzYp4XAADgKVzzAgAAPIXwAgAAPIXwAgAAPIXwAgAAPIXwAgAAPIXwAgAAPIXwAgAAPIXwAgAAPOX/AxzYhi0un3VXAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ex4_2(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wby0z-li0cYE"
      },
      "source": [
        "### 4.3\n",
        "Compute the mean rating per user in the training set. What is the summary statistics of the rating means, and how does a histogram look like? <br>\n",
        "Reflect on how a recommender system can take into account if different users rate on different \"scales\" (e.i. a rating of $3$ may be high for one user while low for another).<br>\n",
        "<br>\n",
        "Repeat this exercise with mean rating per item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#extra\n",
        "\n",
        "def plot_dist_mean(df,ff, plot = False):\n",
        "\n",
        "  ba = df.groupby(ff).agg({'overall': 'mean'}).reset_index().drop(ff, axis = 1)\n",
        "  if plot == True:\n",
        "    plt.hist(ba['overall'], weights=np.ones(len(ba['overall'])) / len(ba['overall']), bins = range(7))\n",
        "    plt.xticks(range(7))\n",
        "    plt.title(f'Distribution rarings per {ff}')\n",
        "    plt.show()\n",
        "  return ba.describe()\n",
        "\n",
        "plot_dist_mean(train,'asin', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "69Y_TnMX0cYE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    981.000000\n",
            "mean       4.767839\n",
            "std        0.719835\n",
            "min        1.000000\n",
            "25%        5.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: overall, dtype: float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "user= train.groupby('reviewerID').mean('overall').reset_index()\n",
        "print(user['overall'].describe())\n",
        "plt.hist(user['overall'], weights=np.ones(len(user['overall'])) / len(user['overall']), bins = range(7))\n",
        "plt.xticks(range(7))\n",
        "# plt.title(f'Distribution rarings per {ff}')\n",
        "plt.xlabel('Rating means')\n",
        "plt.ylabel('Percentage of users')\n",
        "plt.show();\n",
        "# user['overall'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    59.000000\n",
            "mean      3.993775\n",
            "std       0.968168\n",
            "min       1.000000\n",
            "25%       3.576923\n",
            "50%       4.213740\n",
            "75%       4.705031\n",
            "max       5.000000\n",
            "Name: overall, dtype: float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# item= train.groupby('asin').mean('overall').reset_index()\n",
        "# item['overall'].describe()\n",
        "\n",
        "item = train.groupby('asin').mean('overall').reset_index()\n",
        "print(item['overall'].describe())\n",
        "plt.hist(item['overall'], weights=np.ones(len(item['overall'])) / len(item['overall']), bins = range(7))\n",
        "plt.xticks(range(7))\n",
        "# plt.title(f'Distribution rarings per {ff}')\n",
        "plt.xlabel('Rating means')\n",
        "plt.ylabel('Percentage of items')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Collaborative Filtering Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FLw9Rihg4zxG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "\n",
        "\n",
        "import surprise \n",
        "\n",
        "from pandas.io.parsers.readers import read_csv\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "from  surprise import KNNWithMeans\n",
        "from surprise import SVD\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqQomEsiLc1_"
      },
      "source": [
        "## Exercise 1\n",
        "In this exercise, we are going to predict the rating of a single user-item pair using a neighborhoodbased\n",
        "method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW8j20O1Ifg2"
      },
      "source": [
        "### 1.1\n",
        "- Represent the ratings from the training set in a user-item matrix where the rows represent\n",
        "users and the columns represent items.\n",
        "- Fill unobserved ratings with 0.\n",
        "Compute the cosine similarities between the user with ‘reviewerID’=‘A25C2M3QF9G7OQ’ and\n",
        "all users that have rated the item with ‘asin’=‘B00EYZY6LQ’.\n",
        "What are the similarities and what are the ratings given by these users on item ‘B00EYZY6LQ’?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tMxe9gI-2l7y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>asin</th>\n",
              "      <th>B000FOI48G</th>\n",
              "      <th>B000GLRREU</th>\n",
              "      <th>B000NKJIXM</th>\n",
              "      <th>B0010ZBORW</th>\n",
              "      <th>B0013NB7DW</th>\n",
              "      <th>B001E96LUO</th>\n",
              "      <th>B001ET7FZE</th>\n",
              "      <th>B001F51RAG</th>\n",
              "      <th>B001LNODUS</th>\n",
              "      <th>B002GP80EU</th>\n",
              "      <th>...</th>\n",
              "      <th>B00EF1QRMU</th>\n",
              "      <th>B00EYZY6LQ</th>\n",
              "      <th>B00L1I1VMG</th>\n",
              "      <th>B00N2WQ2IW</th>\n",
              "      <th>B00W259T7G</th>\n",
              "      <th>B016V8YWBC</th>\n",
              "      <th>B019809F9Y</th>\n",
              "      <th>B019FWRG3C</th>\n",
              "      <th>B01BNEYGQU</th>\n",
              "      <th>B01E7UKR38</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewerID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1F7YU6O5RU432</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1R1BFJCMWX0Y3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1UQBFCERIP7VJ</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A22CW0ZHY3NJH8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A25C2M3QF9G7OQ</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2LW5AL0KQ9P1M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2PD27UKAD3Q00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2WW57XX2UVLM6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2ZY49IDE6TY5I</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A39WWMBA0299ZF</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3M6TSEV71537G</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3S3R88HA0HZG3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A914TQVHI872U</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AOEUN9718KVRD</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "asin            B000FOI48G  B000GLRREU  B000NKJIXM  B0010ZBORW  B0013NB7DW  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         0.0         0.0         4.0         0.0         0.0   \n",
              "A1R1BFJCMWX0Y3         0.0         0.0         0.0         0.0         0.0   \n",
              "A1UQBFCERIP7VJ         0.0         0.0         4.0         2.0         0.0   \n",
              "A22CW0ZHY3NJH8         0.0         0.0         0.0         0.0         0.0   \n",
              "A25C2M3QF9G7OQ         5.0         5.0         2.0         0.0         0.0   \n",
              "A2LW5AL0KQ9P1M         0.0         0.0         0.0         0.0         0.0   \n",
              "A2PD27UKAD3Q00         0.0         0.0         0.0         5.0         0.0   \n",
              "A2WW57XX2UVLM6         0.0         0.0         0.0         0.0         0.0   \n",
              "A2ZY49IDE6TY5I         5.0         5.0         0.0         0.0         0.0   \n",
              "A39WWMBA0299ZF         0.0         0.0         0.0         2.0         0.0   \n",
              "A3M6TSEV71537G         0.0         0.0         0.0         0.0         0.0   \n",
              "A3S3R88HA0HZG3         0.0         0.0         0.0         5.0         0.0   \n",
              "A914TQVHI872U          0.0         0.0         0.0         0.0         5.0   \n",
              "AOEUN9718KVRD          0.0         0.0         3.0         0.0         0.0   \n",
              "\n",
              "asin            B001E96LUO  B001ET7FZE  B001F51RAG  B001LNODUS  B002GP80EU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         4.0         0.0         0.0         0.0         0.0   \n",
              "A1R1BFJCMWX0Y3         0.0         0.0         0.0         0.0         3.0   \n",
              "A1UQBFCERIP7VJ         0.0         5.0         0.0         0.0         0.0   \n",
              "A22CW0ZHY3NJH8         4.0         4.0         4.0         0.0         4.0   \n",
              "A25C2M3QF9G7OQ         0.0         0.0         5.0         0.0         0.0   \n",
              "A2LW5AL0KQ9P1M         0.0         0.0         0.0         0.0         3.0   \n",
              "A2PD27UKAD3Q00         0.0         0.0         0.0         5.0         0.0   \n",
              "A2WW57XX2UVLM6         0.0         0.0         0.0         0.0         0.0   \n",
              "A2ZY49IDE6TY5I         0.0         0.0         0.0         0.0         0.0   \n",
              "A39WWMBA0299ZF         0.0         0.0         0.0         5.0         0.0   \n",
              "A3M6TSEV71537G         0.0         0.0         0.0         0.0         0.0   \n",
              "A3S3R88HA0HZG3         0.0         0.0         0.0         0.0         0.0   \n",
              "A914TQVHI872U          0.0         0.0         0.0         0.0         0.0   \n",
              "AOEUN9718KVRD          0.0         0.0         0.0         2.0         0.0   \n",
              "\n",
              "asin            ...  B00EF1QRMU  B00EYZY6LQ  B00L1I1VMG  B00N2WQ2IW  \\\n",
              "reviewerID      ...                                                   \n",
              "A1F7YU6O5RU432  ...         0.0         5.0         5.0         0.0   \n",
              "A1R1BFJCMWX0Y3  ...         0.0         3.0         0.0         0.0   \n",
              "A1UQBFCERIP7VJ  ...         0.0         5.0         0.0         5.0   \n",
              "A22CW0ZHY3NJH8  ...         0.0         3.0         0.0         0.0   \n",
              "A25C2M3QF9G7OQ  ...         0.0         0.0         0.0         0.0   \n",
              "A2LW5AL0KQ9P1M  ...         2.0         4.0         3.0         0.0   \n",
              "A2PD27UKAD3Q00  ...         0.0         5.0         0.0         0.0   \n",
              "A2WW57XX2UVLM6  ...         3.0         4.0         0.0         0.0   \n",
              "A2ZY49IDE6TY5I  ...         0.0         4.0         0.0         0.0   \n",
              "A39WWMBA0299ZF  ...         0.0         5.0         0.0         0.0   \n",
              "A3M6TSEV71537G  ...         0.0         5.0         4.0         4.0   \n",
              "A3S3R88HA0HZG3  ...         5.0         4.0         4.0         5.0   \n",
              "A914TQVHI872U   ...         0.0         5.0         0.0         0.0   \n",
              "AOEUN9718KVRD   ...         0.0         3.0         0.0         0.0   \n",
              "\n",
              "asin            B00W259T7G  B016V8YWBC  B019809F9Y  B019FWRG3C  B01BNEYGQU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         0.0         0.0         0.0         0.0         0.0   \n",
              "A1R1BFJCMWX0Y3         3.0         0.0         0.0         0.0         0.0   \n",
              "A1UQBFCERIP7VJ         0.0         5.0         0.0         0.0         5.0   \n",
              "A22CW0ZHY3NJH8         0.0         0.0         0.0         0.0         4.0   \n",
              "A25C2M3QF9G7OQ         5.0         0.0         0.0         0.0         0.0   \n",
              "A2LW5AL0KQ9P1M         5.0         0.0         0.0         0.0         0.0   \n",
              "A2PD27UKAD3Q00         0.0         0.0         0.0         0.0         0.0   \n",
              "A2WW57XX2UVLM6         0.0         0.0         0.0         0.0         0.0   \n",
              "A2ZY49IDE6TY5I         5.0         0.0         0.0         0.0         0.0   \n",
              "A39WWMBA0299ZF         0.0         0.0         0.0         0.0         0.0   \n",
              "A3M6TSEV71537G         0.0         0.0         0.0         0.0         0.0   \n",
              "A3S3R88HA0HZG3         0.0         0.0         0.0         0.0         0.0   \n",
              "A914TQVHI872U          5.0         0.0         5.0         0.0         0.0   \n",
              "AOEUN9718KVRD          0.0         0.0         0.0         2.0         0.0   \n",
              "\n",
              "asin            B01E7UKR38  \n",
              "reviewerID                  \n",
              "A1F7YU6O5RU432         4.0  \n",
              "A1R1BFJCMWX0Y3         3.0  \n",
              "A1UQBFCERIP7VJ         0.0  \n",
              "A22CW0ZHY3NJH8         0.0  \n",
              "A25C2M3QF9G7OQ         0.0  \n",
              "A2LW5AL0KQ9P1M         0.0  \n",
              "A2PD27UKAD3Q00         0.0  \n",
              "A2WW57XX2UVLM6         0.0  \n",
              "A2ZY49IDE6TY5I         5.0  \n",
              "A39WWMBA0299ZF         0.0  \n",
              "A3M6TSEV71537G         0.0  \n",
              "A3S3R88HA0HZG3         5.0  \n",
              "A914TQVHI872U          0.0  \n",
              "AOEUN9718KVRD          0.0  \n",
              "\n",
              "[14 rows x 24 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#join other target_user with others\n",
        "the_user = train.loc[train['reviewerID'] =='A25C2M3QF9G7OQ']\n",
        "\n",
        "#retrive all users with corresponding item B00EYZY6LQ\n",
        "new = train.loc[train['asin'] =='B00EYZY6LQ']\n",
        "other_users = train.loc[train['reviewerID'].isin(new['reviewerID'])]\n",
        "\n",
        "joint = pd.concat([the_user, other_users])\n",
        "\n",
        "\n",
        "\n",
        "def user_item_matrix(df):\n",
        "\n",
        "  df = df[['reviewerID', 'asin', 'overall']]\n",
        "\n",
        "  all = df.pivot(*df.columns).fillna(0)\n",
        "\n",
        "  return all\n",
        "\n",
        "coisa = user_item_matrix(joint) \n",
        "# coisa['B00W259T7G']\n",
        "coisa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "aBHtnbaE2l-G",
        "outputId": "c3b64fb2-2878-4755-a8df-2b7cbd529f06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1F7YU6O5RU432</td>\n",
              "      <td>0.079243</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1R1BFJCMWX0Y3</td>\n",
              "      <td>0.245145</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1UQBFCERIP7VJ</td>\n",
              "      <td>0.058634</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A22CW0ZHY3NJH8</td>\n",
              "      <td>0.207883</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LW5AL0KQ9P1M</td>\n",
              "      <td>0.275810</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A2PD27UKAD3Q00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A2WW57XX2UVLM6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A2ZY49IDE6TY5I</td>\n",
              "      <td>0.682835</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A39WWMBA0299ZF</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A3M6TSEV71537G</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A3S3R88HA0HZG3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>A914TQVHI872U</td>\n",
              "      <td>0.245145</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>AOEUN9718KVRD</td>\n",
              "      <td>0.105670</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        reviewerID  cosine_similarity  overall\n",
              "0   A1F7YU6O5RU432           0.079243      5.0\n",
              "1   A1R1BFJCMWX0Y3           0.245145      3.0\n",
              "2   A1UQBFCERIP7VJ           0.058634      5.0\n",
              "3   A22CW0ZHY3NJH8           0.207883      3.0\n",
              "4   A2LW5AL0KQ9P1M           0.275810      4.0\n",
              "5   A2PD27UKAD3Q00           0.000000      5.0\n",
              "6   A2WW57XX2UVLM6           0.000000      4.0\n",
              "7   A2ZY49IDE6TY5I           0.682835      4.0\n",
              "8   A39WWMBA0299ZF           0.000000      5.0\n",
              "9   A3M6TSEV71537G           0.000000      5.0\n",
              "10  A3S3R88HA0HZG3           0.000000      4.0\n",
              "11   A914TQVHI872U           0.245145      5.0\n",
              "12   AOEUN9718KVRD           0.105670      3.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def cosine_sim(df, new):\n",
        "\n",
        "  bab = pd.DataFrame(cosine_similarity(df))\n",
        "  bab.columns = coisa.index\n",
        "  bab.index = coisa.index\n",
        "\n",
        "  bab = pd.DataFrame(bab['A25C2M3QF9G7OQ']).drop('A25C2M3QF9G7OQ').reset_index()\n",
        "\n",
        "  bab.columns = ['reviewerID', 'cosine_similarity']\n",
        "  bab =bab.sort_values(by = ['reviewerID']).reset_index()\n",
        "\n",
        "  new = new.sort_values(by = ['reviewerID']).reset_index()\n",
        "\n",
        "\n",
        "  bab['overall'] = pd.DataFrame(new['overall'])\n",
        "\n",
        "  return bab.drop(['index'], axis = 1)\n",
        "\n",
        "oi =cosine_sim(coisa, new)\n",
        "\n",
        "oi\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A2ZY49IDE6TY5I</td>\n",
              "      <td>0.682835</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LW5AL0KQ9P1M</td>\n",
              "      <td>0.275810</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1R1BFJCMWX0Y3</td>\n",
              "      <td>0.245145</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID  cosine_similarity  overall\n",
              "7  A2ZY49IDE6TY5I           0.682835      4.0\n",
              "4  A2LW5AL0KQ9P1M           0.275810      4.0\n",
              "1  A1R1BFJCMWX0Y3           0.245145      3.0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oi.sort_values(by =['cosine_similarity'], ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn5F193pIZ4t"
      },
      "source": [
        "### 1.2\n",
        "Predict the rating for user ‘A25C2M3QF9G7OQ’ on item ‘B00EYZY6LQ’ based on the ratings from\n",
        "the 3 most similar users, using a weighted (by similarity) average. What is the prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "ujkYCNFN2mAQ",
        "outputId": "e6dc1d72-4678-4570-a0b4-57d3a4e20626"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1F7YU6O5RU432</td>\n",
              "      <td>0.079243</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1R1BFJCMWX0Y3</td>\n",
              "      <td>0.245145</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1UQBFCERIP7VJ</td>\n",
              "      <td>0.058634</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A22CW0ZHY3NJH8</td>\n",
              "      <td>0.207883</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LW5AL0KQ9P1M</td>\n",
              "      <td>0.275810</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A2PD27UKAD3Q00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A2WW57XX2UVLM6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A2ZY49IDE6TY5I</td>\n",
              "      <td>0.682835</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A39WWMBA0299ZF</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A3M6TSEV71537G</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A3S3R88HA0HZG3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>A914TQVHI872U</td>\n",
              "      <td>0.245145</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>AOEUN9718KVRD</td>\n",
              "      <td>0.105670</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        reviewerID  cosine_similarity  overall\n",
              "0   A1F7YU6O5RU432           0.079243      5.0\n",
              "1   A1R1BFJCMWX0Y3           0.245145      3.0\n",
              "2   A1UQBFCERIP7VJ           0.058634      5.0\n",
              "3   A22CW0ZHY3NJH8           0.207883      3.0\n",
              "4   A2LW5AL0KQ9P1M           0.275810      4.0\n",
              "5   A2PD27UKAD3Q00           0.000000      5.0\n",
              "6   A2WW57XX2UVLM6           0.000000      4.0\n",
              "7   A2ZY49IDE6TY5I           0.682835      4.0\n",
              "8   A39WWMBA0299ZF           0.000000      5.0\n",
              "9   A3M6TSEV71537G           0.000000      5.0\n",
              "10  A3S3R88HA0HZG3           0.000000      4.0\n",
              "11   A914TQVHI872U           0.245145      5.0\n",
              "12   AOEUN9718KVRD           0.105670      3.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import data from solutions sheet :) \n",
        "#COMPARE WITH MY OWN RESULTS\n",
        "\n",
        "data = read_csv('results.txt', sep = ' ')\n",
        "\n",
        "data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "gj94lQ3ZAbi9",
        "outputId": "4ba66974-991c-4357-d01e-fb486c53acee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.7963554954121093"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict(data):\n",
        "\n",
        "    # data.colunames = ['reviewerID', 'cosine_similarity', 'overall']\n",
        "    data = data.sort_values(by = ['cosine_similarity'], ascending= False).head(3)\n",
        "\n",
        "\n",
        "    #FOR THIS PURPOSE I'LL USE RESULTS.TXT\n",
        "\n",
        "    data['new'] = data['cosine_similarity'] * data['overall']\n",
        "\n",
        "    return sum(data['new'])/ sum(data['cosine_similarity'])\n",
        "\n",
        "# predict(data)\n",
        "prep = oi.sort_values(by =['cosine_similarity'], ascending=False).head(3)\n",
        "\n",
        "predict(prep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2\n",
        "In this exercise, we are going to predict the rating of the same user-item pair as in exercise 1, now\n",
        "using a latent factor method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1\n",
        "- Represent the ratings from the training set in a user-item matrix where the rows represent\n",
        "users and the columns represent items.\n",
        "- Subtract the row mean (i.e. mean rating per user) from each non-missing element in the\n",
        "matrix.\n",
        "- Replace missing values with 0.\n",
        "Factorize the user-item matrix by performing Singular Value Decomposition (SVD) of rank 5 using\n",
        "eigendecomposition. What is ther user factors of user ‘A25C2M3QF9G7OQ’ and the item factors\n",
        "of item ‘B00EYZY6LQ’?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>asin</th>\n",
              "      <th>B000FOI48G</th>\n",
              "      <th>B000GLRREU</th>\n",
              "      <th>B000NKJIXM</th>\n",
              "      <th>B0010ZBORW</th>\n",
              "      <th>B0013NB7DW</th>\n",
              "      <th>B001E96LUO</th>\n",
              "      <th>B001ET7FZE</th>\n",
              "      <th>B001F51RAG</th>\n",
              "      <th>B001LNODUS</th>\n",
              "      <th>B002GP80EU</th>\n",
              "      <th>...</th>\n",
              "      <th>B00EF1QRMU</th>\n",
              "      <th>B00EYZY6LQ</th>\n",
              "      <th>B00L1I1VMG</th>\n",
              "      <th>B00N2WQ2IW</th>\n",
              "      <th>B00W259T7G</th>\n",
              "      <th>B016V8YWBC</th>\n",
              "      <th>B019809F9Y</th>\n",
              "      <th>B019FWRG3C</th>\n",
              "      <th>B01BNEYGQU</th>\n",
              "      <th>B01E7UKR38</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewerID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1F7YU6O5RU432</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1R1BFJCMWX0Y3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1UQBFCERIP7VJ</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-2.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A22CW0ZHY3NJH8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A25C2M3QF9G7OQ</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2LW5AL0KQ9P1M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2PD27UKAD3Q00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2WW57XX2UVLM6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2ZY49IDE6TY5I</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A39WWMBA0299ZF</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3M6TSEV71537G</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3S3R88HA0HZG3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A914TQVHI872U</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AOEUN9718KVRD</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "asin            B000FOI48G  B000GLRREU  B000NKJIXM  B0010ZBORW  B0013NB7DW  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         0.0         0.0   -0.400000    0.000000         0.0   \n",
              "A1R1BFJCMWX0Y3         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A1UQBFCERIP7VJ         0.0         0.0   -0.333333   -2.333333         0.0   \n",
              "A22CW0ZHY3NJH8         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A25C2M3QF9G7OQ         0.6         0.6   -2.400000    0.000000         0.0   \n",
              "A2LW5AL0KQ9P1M         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2PD27UKAD3Q00         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2WW57XX2UVLM6         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2ZY49IDE6TY5I         0.2         0.2    0.000000    0.000000         0.0   \n",
              "A39WWMBA0299ZF         0.0         0.0    0.000000   -2.000000         0.0   \n",
              "A3M6TSEV71537G         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A3S3R88HA0HZG3         0.0         0.0    0.000000    0.333333         0.0   \n",
              "A914TQVHI872U          0.0         0.0    0.000000    0.000000         0.0   \n",
              "AOEUN9718KVRD          0.0         0.0    0.833333    0.000000         0.0   \n",
              "\n",
              "asin            B001E96LUO  B001ET7FZE  B001F51RAG  B001LNODUS  B002GP80EU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432   -0.400000    0.000000    0.000000    0.000000    0.000000   \n",
              "A1R1BFJCMWX0Y3    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A1UQBFCERIP7VJ    0.000000    0.666667    0.000000    0.000000    0.000000   \n",
              "A22CW0ZHY3NJH8    0.166667    0.166667    0.166667    0.000000    0.166667   \n",
              "A25C2M3QF9G7OQ    0.000000    0.000000    0.600000    0.000000    0.000000   \n",
              "A2LW5AL0KQ9P1M    0.000000    0.000000    0.000000    0.000000   -0.500000   \n",
              "A2PD27UKAD3Q00    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A2WW57XX2UVLM6    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A2ZY49IDE6TY5I    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A39WWMBA0299ZF    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
              "A3M6TSEV71537G    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A3S3R88HA0HZG3    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "A914TQVHI872U     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "AOEUN9718KVRD     0.000000    0.000000    0.000000   -0.166667    0.000000   \n",
              "\n",
              "asin            ...  B00EF1QRMU  B00EYZY6LQ  B00L1I1VMG  B00N2WQ2IW  \\\n",
              "reviewerID      ...                                                   \n",
              "A1F7YU6O5RU432  ...    0.000000    0.600000    0.600000    0.000000   \n",
              "A1R1BFJCMWX0Y3  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A1UQBFCERIP7VJ  ...    0.000000    0.666667    0.000000    0.666667   \n",
              "A22CW0ZHY3NJH8  ...    0.000000   -0.833333    0.000000    0.000000   \n",
              "A25C2M3QF9G7OQ  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A2LW5AL0KQ9P1M  ...   -1.500000    0.500000   -0.500000    0.000000   \n",
              "A2PD27UKAD3Q00  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A2WW57XX2UVLM6  ...   -0.333333    0.666667    0.000000    0.000000   \n",
              "A2ZY49IDE6TY5I  ...    0.000000   -0.800000    0.000000    0.000000   \n",
              "A39WWMBA0299ZF  ...    0.000000    1.000000    0.000000    0.000000   \n",
              "A3M6TSEV71537G  ...    0.000000    0.666667   -0.333333   -0.333333   \n",
              "A3S3R88HA0HZG3  ...    0.333333   -0.666667   -0.666667    0.333333   \n",
              "A914TQVHI872U   ...    0.000000    0.000000    0.000000    0.000000   \n",
              "AOEUN9718KVRD   ...    0.000000    0.833333    0.000000    0.000000   \n",
              "\n",
              "asin            B00W259T7G  B016V8YWBC  B019809F9Y  B019FWRG3C  B01BNEYGQU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A1R1BFJCMWX0Y3         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A1UQBFCERIP7VJ         0.0    0.666667         0.0    0.000000    0.666667   \n",
              "A22CW0ZHY3NJH8         0.0    0.000000         0.0    0.000000    0.166667   \n",
              "A25C2M3QF9G7OQ         0.6    0.000000         0.0    0.000000    0.000000   \n",
              "A2LW5AL0KQ9P1M         1.5    0.000000         0.0    0.000000    0.000000   \n",
              "A2PD27UKAD3Q00         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A2WW57XX2UVLM6         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A2ZY49IDE6TY5I         0.2    0.000000         0.0    0.000000    0.000000   \n",
              "A39WWMBA0299ZF         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A3M6TSEV71537G         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A3S3R88HA0HZG3         0.0    0.000000         0.0    0.000000    0.000000   \n",
              "A914TQVHI872U          0.0    0.000000         0.0    0.000000    0.000000   \n",
              "AOEUN9718KVRD          0.0    0.000000         0.0   -0.166667    0.000000   \n",
              "\n",
              "asin            B01E7UKR38  \n",
              "reviewerID                  \n",
              "A1F7YU6O5RU432   -0.400000  \n",
              "A1R1BFJCMWX0Y3    0.000000  \n",
              "A1UQBFCERIP7VJ    0.000000  \n",
              "A22CW0ZHY3NJH8    0.000000  \n",
              "A25C2M3QF9G7OQ    0.000000  \n",
              "A2LW5AL0KQ9P1M    0.000000  \n",
              "A2PD27UKAD3Q00    0.000000  \n",
              "A2WW57XX2UVLM6    0.000000  \n",
              "A2ZY49IDE6TY5I    0.200000  \n",
              "A39WWMBA0299ZF    0.000000  \n",
              "A3M6TSEV71537G    0.000000  \n",
              "A3S3R88HA0HZG3    0.333333  \n",
              "A914TQVHI872U     0.000000  \n",
              "AOEUN9718KVRD     0.000000  \n",
              "\n",
              "[14 rows x 24 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def user_item_matrix_2_1(df):\n",
        "\n",
        "  df = df[['reviewerID', 'asin', 'overall']]\n",
        "\n",
        "  all = df.pivot(*df.columns)\n",
        "\n",
        "  #add mean collumn \n",
        "  all['mean'] = all.mean(axis=1)\n",
        "\n",
        "  #Subtract the row mean (i.e. mean rating per user) from each non-missing element in the matrix.\n",
        "  #Replace missing values with 0.\n",
        "  all = all.subtract(all['mean'], axis = 0).fillna(0)\n",
        "\n",
        "\n",
        "  return all.drop(['mean'], axis=1)\n",
        "\n",
        "ratings_matrix_2_1 = user_item_matrix_2_1(joint) \n",
        "\n",
        "ratings_matrix_2_1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.sparse.linalg import svds\n",
        "import scipy\n",
        "# import numpy.random.RandomState as random\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.135976e-02</td>\n",
              "      <td>9.135976e-02</td>\n",
              "      <td>-4.192046e-01</td>\n",
              "      <td>-2.261449e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.077629e-01</td>\n",
              "      <td>-5.184233e-02</td>\n",
              "      <td>9.637840e-02</td>\n",
              "      <td>7.591786e-03</td>\n",
              "      <td>3.175698e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>8.272567e-02</td>\n",
              "      <td>6.773329e-01</td>\n",
              "      <td>2.534994e-01</td>\n",
              "      <td>-1.121977e-01</td>\n",
              "      <td>-7.583763e-02</td>\n",
              "      <td>-2.786685e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.641300e-02</td>\n",
              "      <td>-5.184233e-02</td>\n",
              "      <td>-1.649204e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.567684e-21</td>\n",
              "      <td>5.567684e-21</td>\n",
              "      <td>7.985527e-21</td>\n",
              "      <td>3.517677e-19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.365813e-21</td>\n",
              "      <td>-5.071713e-20</td>\n",
              "      <td>6.508120e-21</td>\n",
              "      <td>-9.216019e-20</td>\n",
              "      <td>3.003253e-20</td>\n",
              "      <td>...</td>\n",
              "      <td>9.330514e-20</td>\n",
              "      <td>-1.277551e-19</td>\n",
              "      <td>4.048529e-20</td>\n",
              "      <td>-4.931522e-20</td>\n",
              "      <td>-8.698461e-20</td>\n",
              "      <td>-4.989890e-20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.977814e-21</td>\n",
              "      <td>-5.071713e-20</td>\n",
              "      <td>-8.549409e-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.567866e-02</td>\n",
              "      <td>3.567866e-02</td>\n",
              "      <td>-3.255582e-01</td>\n",
              "      <td>-2.353808e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.846342e-02</td>\n",
              "      <td>6.536026e-01</td>\n",
              "      <td>4.043375e-02</td>\n",
              "      <td>4.369323e-02</td>\n",
              "      <td>1.829399e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>1.913617e-02</td>\n",
              "      <td>6.418924e-01</td>\n",
              "      <td>-3.418884e-02</td>\n",
              "      <td>6.785545e-01</td>\n",
              "      <td>1.602662e-02</td>\n",
              "      <td>6.418593e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.868262e-02</td>\n",
              "      <td>6.536026e-01</td>\n",
              "      <td>4.115984e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.640415e-03</td>\n",
              "      <td>6.640415e-03</td>\n",
              "      <td>-2.906420e-02</td>\n",
              "      <td>5.504798e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.973196e-02</td>\n",
              "      <td>6.916404e-02</td>\n",
              "      <td>3.480739e-03</td>\n",
              "      <td>-5.858217e-02</td>\n",
              "      <td>3.280293e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>1.095268e-01</td>\n",
              "      <td>-7.052321e-01</td>\n",
              "      <td>-1.382065e-01</td>\n",
              "      <td>1.257856e-01</td>\n",
              "      <td>-2.519598e-02</td>\n",
              "      <td>4.697324e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.759179e-02</td>\n",
              "      <td>6.916404e-02</td>\n",
              "      <td>1.299980e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.343087e-01</td>\n",
              "      <td>5.343087e-01</td>\n",
              "      <td>-2.406001e+00</td>\n",
              "      <td>4.058672e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.543316e-02</td>\n",
              "      <td>2.668103e-02</td>\n",
              "      <td>5.308594e-01</td>\n",
              "      <td>-5.168916e-02</td>\n",
              "      <td>-1.947401e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.101207e-02</td>\n",
              "      <td>1.823076e-02</td>\n",
              "      <td>1.345976e-01</td>\n",
              "      <td>8.026784e-03</td>\n",
              "      <td>5.771390e-01</td>\n",
              "      <td>3.187827e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.311982e-02</td>\n",
              "      <td>2.668103e-02</td>\n",
              "      <td>-9.944121e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.691939e-02</td>\n",
              "      <td>2.691939e-02</td>\n",
              "      <td>-3.116234e-04</td>\n",
              "      <td>1.782214e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.104859e-02</td>\n",
              "      <td>-1.227162e-02</td>\n",
              "      <td>1.359475e-02</td>\n",
              "      <td>1.082557e-02</td>\n",
              "      <td>-4.888479e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.487327e+00</td>\n",
              "      <td>5.170158e-01</td>\n",
              "      <td>-5.693512e-01</td>\n",
              "      <td>-2.418895e-02</td>\n",
              "      <td>1.482851e+00</td>\n",
              "      <td>-8.734244e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.852756e-03</td>\n",
              "      <td>-1.227162e-02</td>\n",
              "      <td>5.494224e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2.585759e-17</td>\n",
              "      <td>-2.585759e-17</td>\n",
              "      <td>1.484902e-16</td>\n",
              "      <td>5.322564e-17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.305065e-18</td>\n",
              "      <td>5.921912e-17</td>\n",
              "      <td>-2.433815e-17</td>\n",
              "      <td>-1.400610e-16</td>\n",
              "      <td>8.946108e-19</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.496840e-18</td>\n",
              "      <td>-2.678878e-18</td>\n",
              "      <td>-1.356339e-17</td>\n",
              "      <td>6.680966e-17</td>\n",
              "      <td>-2.540228e-17</td>\n",
              "      <td>5.817274e-17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.475596e-17</td>\n",
              "      <td>5.921912e-17</td>\n",
              "      <td>8.005797e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.667314e-03</td>\n",
              "      <td>1.667314e-03</td>\n",
              "      <td>1.754214e-02</td>\n",
              "      <td>-1.022152e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.409140e-02</td>\n",
              "      <td>2.064279e-02</td>\n",
              "      <td>4.012004e-03</td>\n",
              "      <td>-5.684469e-02</td>\n",
              "      <td>-6.323886e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.045002e-01</td>\n",
              "      <td>5.792816e-01</td>\n",
              "      <td>4.735312e-02</td>\n",
              "      <td>-1.553292e-02</td>\n",
              "      <td>1.455079e-01</td>\n",
              "      <td>3.593479e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.030499e-02</td>\n",
              "      <td>2.064279e-02</td>\n",
              "      <td>-8.595896e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.036831e-02</td>\n",
              "      <td>2.036831e-02</td>\n",
              "      <td>-8.518496e-02</td>\n",
              "      <td>8.887467e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.911366e-02</td>\n",
              "      <td>4.441947e-02</td>\n",
              "      <td>1.588148e-02</td>\n",
              "      <td>-3.234158e-02</td>\n",
              "      <td>-3.342763e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>7.100529e-04</td>\n",
              "      <td>-6.692645e-01</td>\n",
              "      <td>-1.716928e-01</td>\n",
              "      <td>9.721192e-02</td>\n",
              "      <td>9.377278e-02</td>\n",
              "      <td>2.329407e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.050037e-02</td>\n",
              "      <td>4.441947e-02</td>\n",
              "      <td>1.283205e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-6.345378e-02</td>\n",
              "      <td>-6.345378e-02</td>\n",
              "      <td>-1.063463e-02</td>\n",
              "      <td>-1.963639e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.796424e-02</td>\n",
              "      <td>2.722158e-02</td>\n",
              "      <td>-6.524772e-02</td>\n",
              "      <td>9.170692e-01</td>\n",
              "      <td>-2.170149e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.904084e-02</td>\n",
              "      <td>1.036598e+00</td>\n",
              "      <td>9.989855e-02</td>\n",
              "      <td>-3.919102e-02</td>\n",
              "      <td>-4.143629e-02</td>\n",
              "      <td>4.158390e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.595647e-02</td>\n",
              "      <td>2.722158e-02</td>\n",
              "      <td>-8.204022e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-6.009174e-03</td>\n",
              "      <td>-6.009174e-03</td>\n",
              "      <td>2.717877e-02</td>\n",
              "      <td>-4.844859e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.448331e-02</td>\n",
              "      <td>-5.434031e-02</td>\n",
              "      <td>-4.343460e-03</td>\n",
              "      <td>5.619431e-02</td>\n",
              "      <td>-3.988854e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.277758e-01</td>\n",
              "      <td>5.177381e-01</td>\n",
              "      <td>7.823447e-02</td>\n",
              "      <td>-9.533566e-02</td>\n",
              "      <td>6.609754e-02</td>\n",
              "      <td>-3.848734e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.852070e-02</td>\n",
              "      <td>-5.434031e-02</td>\n",
              "      <td>-8.987331e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-4.591137e-03</td>\n",
              "      <td>-4.591137e-03</td>\n",
              "      <td>5.460380e-02</td>\n",
              "      <td>2.659720e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.611986e-02</td>\n",
              "      <td>5.845623e-02</td>\n",
              "      <td>-7.869960e-03</td>\n",
              "      <td>-1.443690e-01</td>\n",
              "      <td>2.269969e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>7.987543e-02</td>\n",
              "      <td>-7.993218e-01</td>\n",
              "      <td>-1.668055e-01</td>\n",
              "      <td>1.215404e-01</td>\n",
              "      <td>-2.030588e-03</td>\n",
              "      <td>3.490303e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.324080e-02</td>\n",
              "      <td>5.845623e-02</td>\n",
              "      <td>1.423118e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-8.584999e-18</td>\n",
              "      <td>-8.584999e-18</td>\n",
              "      <td>-2.130586e-17</td>\n",
              "      <td>-4.191231e-16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.089566e-17</td>\n",
              "      <td>2.000264e-17</td>\n",
              "      <td>-1.012822e-17</td>\n",
              "      <td>1.884295e-16</td>\n",
              "      <td>-1.702382e-17</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.061877e-17</td>\n",
              "      <td>1.063170e-16</td>\n",
              "      <td>-2.682000e-17</td>\n",
              "      <td>1.624922e-17</td>\n",
              "      <td>4.587168e-17</td>\n",
              "      <td>1.887424e-17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.333250e-17</td>\n",
              "      <td>2.000264e-17</td>\n",
              "      <td>9.569505e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-1.558318e-01</td>\n",
              "      <td>-1.558318e-01</td>\n",
              "      <td>7.927135e-01</td>\n",
              "      <td>1.234393e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.098300e-02</td>\n",
              "      <td>4.713870e-02</td>\n",
              "      <td>-1.468232e-01</td>\n",
              "      <td>-2.990477e-01</td>\n",
              "      <td>-3.915006e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.417664e-01</td>\n",
              "      <td>9.548079e-01</td>\n",
              "      <td>1.394503e-01</td>\n",
              "      <td>-8.792497e-03</td>\n",
              "      <td>-1.211570e-01</td>\n",
              "      <td>7.473049e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.330889e-02</td>\n",
              "      <td>4.713870e-02</td>\n",
              "      <td>-1.464732e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0             1             2             3    4             5   \\\n",
              "0   9.135976e-02  9.135976e-02 -4.192046e-01 -2.261449e-02  0.0 -1.077629e-01   \n",
              "1   5.567684e-21  5.567684e-21  7.985527e-21  3.517677e-19  0.0 -8.365813e-21   \n",
              "2   3.567866e-02  3.567866e-02 -3.255582e-01 -2.353808e+00  0.0  2.846342e-02   \n",
              "3   6.640415e-03  6.640415e-03 -2.906420e-02  5.504798e-02  0.0  7.973196e-02   \n",
              "4   5.343087e-01  5.343087e-01 -2.406001e+00  4.058672e-02  0.0 -8.543316e-02   \n",
              "5   2.691939e-02  2.691939e-02 -3.116234e-04  1.782214e-03  0.0  4.104859e-02   \n",
              "6  -2.585759e-17 -2.585759e-17  1.484902e-16  5.322564e-17  0.0  3.305065e-18   \n",
              "7   1.667314e-03  1.667314e-03  1.754214e-02 -1.022152e-01  0.0 -5.409140e-02   \n",
              "8   2.036831e-02  2.036831e-02 -8.518496e-02  8.887467e-02  0.0  7.911366e-02   \n",
              "9  -6.345378e-02 -6.345378e-02 -1.063463e-02 -1.963639e+00  0.0 -2.796424e-02   \n",
              "10 -6.009174e-03 -6.009174e-03  2.717877e-02 -4.844859e-02  0.0 -5.448331e-02   \n",
              "11 -4.591137e-03 -4.591137e-03  5.460380e-02  2.659720e-01  0.0  8.611986e-02   \n",
              "12 -8.584999e-18 -8.584999e-18 -2.130586e-17 -4.191231e-16  0.0  1.089566e-17   \n",
              "13 -1.558318e-01 -1.558318e-01  7.927135e-01  1.234393e-01  0.0 -9.098300e-02   \n",
              "\n",
              "              6             7             8             9   ...            14  \\\n",
              "0  -5.184233e-02  9.637840e-02  7.591786e-03  3.175698e-02  ...  8.272567e-02   \n",
              "1  -5.071713e-20  6.508120e-21 -9.216019e-20  3.003253e-20  ...  9.330514e-20   \n",
              "2   6.536026e-01  4.043375e-02  4.369323e-02  1.829399e-02  ...  1.913617e-02   \n",
              "3   6.916404e-02  3.480739e-03 -5.858217e-02  3.280293e-02  ...  1.095268e-01   \n",
              "4   2.668103e-02  5.308594e-01 -5.168916e-02 -1.947401e-02  ... -7.101207e-02   \n",
              "5  -1.227162e-02  1.359475e-02  1.082557e-02 -4.888479e-01  ... -1.487327e+00   \n",
              "6   5.921912e-17 -2.433815e-17 -1.400610e-16  8.946108e-19  ... -1.496840e-18   \n",
              "7   2.064279e-02  4.012004e-03 -5.684469e-02 -6.323886e-02  ... -2.045002e-01   \n",
              "8   4.441947e-02  1.588148e-02 -3.234158e-02 -3.342763e-03  ...  7.100529e-04   \n",
              "9   2.722158e-02 -6.524772e-02  9.170692e-01 -2.170149e-02  ... -6.904084e-02   \n",
              "10 -5.434031e-02 -4.343460e-03  5.619431e-02 -3.988854e-02  ... -1.277758e-01   \n",
              "11  5.845623e-02 -7.869960e-03 -1.443690e-01  2.269969e-02  ...  7.987543e-02   \n",
              "12  2.000264e-17 -1.012822e-17  1.884295e-16 -1.702382e-17  ... -5.061877e-17   \n",
              "13  4.713870e-02 -1.468232e-01 -2.990477e-01 -3.915006e-02  ... -1.417664e-01   \n",
              "\n",
              "              15            16            17            18            19   20  \\\n",
              "0   6.773329e-01  2.534994e-01 -1.121977e-01 -7.583763e-02 -2.786685e-02  0.0   \n",
              "1  -1.277551e-19  4.048529e-20 -4.931522e-20 -8.698461e-20 -4.989890e-20  0.0   \n",
              "2   6.418924e-01 -3.418884e-02  6.785545e-01  1.602662e-02  6.418593e-01  0.0   \n",
              "3  -7.052321e-01 -1.382065e-01  1.257856e-01 -2.519598e-02  4.697324e-02  0.0   \n",
              "4   1.823076e-02  1.345976e-01  8.026784e-03  5.771390e-01  3.187827e-02  0.0   \n",
              "5   5.170158e-01 -5.693512e-01 -2.418895e-02  1.482851e+00 -8.734244e-03  0.0   \n",
              "6  -2.678878e-18 -1.356339e-17  6.680966e-17 -2.540228e-17  5.817274e-17  0.0   \n",
              "7   5.792816e-01  4.735312e-02 -1.553292e-02  1.455079e-01  3.593479e-02  0.0   \n",
              "8  -6.692645e-01 -1.716928e-01  9.721192e-02  9.377278e-02  2.329407e-02  0.0   \n",
              "9   1.036598e+00  9.989855e-02 -3.919102e-02 -4.143629e-02  4.158390e-02  0.0   \n",
              "10  5.177381e-01  7.823447e-02 -9.533566e-02  6.609754e-02 -3.848734e-02  0.0   \n",
              "11 -7.993218e-01 -1.668055e-01  1.215404e-01 -2.030588e-03  3.490303e-02  0.0   \n",
              "12  1.063170e-16 -2.682000e-17  1.624922e-17  4.587168e-17  1.887424e-17  0.0   \n",
              "13  9.548079e-01  1.394503e-01 -8.792497e-03 -1.211570e-01  7.473049e-02  0.0   \n",
              "\n",
              "              21            22            23  \n",
              "0  -2.641300e-02 -5.184233e-02 -1.649204e-01  \n",
              "1  -3.977814e-21 -5.071713e-20 -8.549409e-21  \n",
              "2  -1.868262e-02  6.536026e-01  4.115984e-02  \n",
              "3   2.759179e-02  6.916404e-02  1.299980e-01  \n",
              "4   3.311982e-02  2.668103e-02 -9.944121e-02  \n",
              "5  -3.852756e-03 -1.227162e-02  5.494224e-02  \n",
              "6  -1.475596e-17  5.921912e-17  8.005797e-18  \n",
              "7  -3.030499e-02  2.064279e-02 -8.595896e-02  \n",
              "8   3.050037e-02  4.441947e-02  1.283205e-01  \n",
              "9   3.595647e-02  2.722158e-02 -8.204022e-02  \n",
              "10 -1.852070e-02 -5.434031e-02 -8.987331e-02  \n",
              "11  2.324080e-02  5.845623e-02  1.423118e-01  \n",
              "12  1.333250e-17  2.000264e-17  9.569505e-18  \n",
              "13 -8.330889e-02  4.713870e-02 -1.464732e-01  \n",
              "\n",
              "[14 rows x 24 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'toarray'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-c33350e1aa4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings_matrix_2_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toarray'"
          ]
        }
      ],
      "source": [
        "# SVD usiing scipy pkg\n",
        "# import scipy\n",
        "\n",
        "u , s ,vT = scipy.sparse.linalg.svds(ratings_matrix_2_1, solver='arpack', k = 5)\n",
        "\n",
        "\n",
        "A2 = u @ np.diag(s) @ vT\n",
        "\n",
        "pd.DataFrame(A2)\n",
        "\n",
        "np.allclose(A2, ratings_matrix_2_1.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.220197e-01</td>\n",
              "      <td>2.525227e-01</td>\n",
              "      <td>-1.564564e-01</td>\n",
              "      <td>7.778729e-01</td>\n",
              "      <td>-1.955129e-01</td>\n",
              "      <td>4.841912e-01</td>\n",
              "      <td>-2.197429e-01</td>\n",
              "      <td>-2.530831e-01</td>\n",
              "      <td>7.386638e-02</td>\n",
              "      <td>-1.463219e-02</td>\n",
              "      <td>1.108872e-01</td>\n",
              "      <td>-1.801567e-32</td>\n",
              "      <td>-3.093406e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.224349e-16</td>\n",
              "      <td>-1.600024e-16</td>\n",
              "      <td>6.792698e-17</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.622334e-16</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-7.384497e-17</td>\n",
              "      <td>-1.419436e-16</td>\n",
              "      <td>-8.731441e-17</td>\n",
              "      <td>-8.995230e-17</td>\n",
              "      <td>-4.861635e-17</td>\n",
              "      <td>2.254085e-16</td>\n",
              "      <td>7.897691e-18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.966359e+00</td>\n",
              "      <td>2.712726e-02</td>\n",
              "      <td>6.088891e-01</td>\n",
              "      <td>-6.641508e-01</td>\n",
              "      <td>-5.974515e-01</td>\n",
              "      <td>1.616263e-01</td>\n",
              "      <td>6.179983e-02</td>\n",
              "      <td>-3.136048e-03</td>\n",
              "      <td>1.895443e-02</td>\n",
              "      <td>-2.838913e-02</td>\n",
              "      <td>-8.566457e-03</td>\n",
              "      <td>-1.343028e-32</td>\n",
              "      <td>2.349413e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.066357e-01</td>\n",
              "      <td>1.468336e-01</td>\n",
              "      <td>4.457920e-01</td>\n",
              "      <td>-5.581242e-01</td>\n",
              "      <td>6.530943e-02</td>\n",
              "      <td>-4.749686e-02</td>\n",
              "      <td>-3.229043e-01</td>\n",
              "      <td>2.158637e-01</td>\n",
              "      <td>1.358611e-01</td>\n",
              "      <td>1.506529e-01</td>\n",
              "      <td>9.473350e-02</td>\n",
              "      <td>7.729667e-32</td>\n",
              "      <td>-2.623560e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.096751e-01</td>\n",
              "      <td>2.595431e+00</td>\n",
              "      <td>9.669401e-02</td>\n",
              "      <td>4.523450e-01</td>\n",
              "      <td>-1.850614e-01</td>\n",
              "      <td>-3.411233e-01</td>\n",
              "      <td>-3.855826e-02</td>\n",
              "      <td>3.328887e-02</td>\n",
              "      <td>-7.363256e-03</td>\n",
              "      <td>1.534451e-02</td>\n",
              "      <td>-1.945994e-02</td>\n",
              "      <td>2.715965e-32</td>\n",
              "      <td>4.717572e-34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-3.745433e-01</td>\n",
              "      <td>5.418049e-01</td>\n",
              "      <td>-2.092535e+00</td>\n",
              "      <td>-8.119706e-01</td>\n",
              "      <td>1.170348e-01</td>\n",
              "      <td>9.126031e-02</td>\n",
              "      <td>-5.077466e-02</td>\n",
              "      <td>-4.678996e-02</td>\n",
              "      <td>3.688325e-02</td>\n",
              "      <td>3.287550e-03</td>\n",
              "      <td>-1.713155e-03</td>\n",
              "      <td>1.353554e-32</td>\n",
              "      <td>3.134298e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-5.196198e-17</td>\n",
              "      <td>-3.244667e-16</td>\n",
              "      <td>-1.263394e-16</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.910480e-17</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.605883e-17</td>\n",
              "      <td>6.831491e-17</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-3.935669e-01</td>\n",
              "      <td>-7.189521e-02</td>\n",
              "      <td>-4.641707e-01</td>\n",
              "      <td>2.519272e-01</td>\n",
              "      <td>-2.445528e-01</td>\n",
              "      <td>1.367196e-01</td>\n",
              "      <td>2.348153e-01</td>\n",
              "      <td>1.161182e-01</td>\n",
              "      <td>-2.348996e-01</td>\n",
              "      <td>1.362912e-01</td>\n",
              "      <td>8.251095e-02</td>\n",
              "      <td>-1.655823e-32</td>\n",
              "      <td>-3.454950e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.262375e-01</td>\n",
              "      <td>2.503273e-01</td>\n",
              "      <td>2.800543e-01</td>\n",
              "      <td>-5.695735e-01</td>\n",
              "      <td>1.266431e-01</td>\n",
              "      <td>-1.613348e-01</td>\n",
              "      <td>-3.417890e-01</td>\n",
              "      <td>1.540895e-02</td>\n",
              "      <td>-1.585979e-01</td>\n",
              "      <td>-1.917210e-01</td>\n",
              "      <td>8.382180e-02</td>\n",
              "      <td>-4.872415e-32</td>\n",
              "      <td>-9.767686e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-2.130713e+00</td>\n",
              "      <td>-2.929638e-01</td>\n",
              "      <td>-4.387701e-02</td>\n",
              "      <td>4.051736e-01</td>\n",
              "      <td>1.043595e+00</td>\n",
              "      <td>-3.290386e-01</td>\n",
              "      <td>-8.711071e-02</td>\n",
              "      <td>-3.796881e-02</td>\n",
              "      <td>-1.444465e-02</td>\n",
              "      <td>3.502605e-02</td>\n",
              "      <td>1.796569e-02</td>\n",
              "      <td>-2.788218e-32</td>\n",
              "      <td>-6.207624e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-2.319098e-01</td>\n",
              "      <td>-9.293903e-02</td>\n",
              "      <td>-3.870959e-01</td>\n",
              "      <td>3.718768e-01</td>\n",
              "      <td>-1.743069e-02</td>\n",
              "      <td>-1.479687e-01</td>\n",
              "      <td>4.518882e-01</td>\n",
              "      <td>2.143820e-01</td>\n",
              "      <td>1.241324e-01</td>\n",
              "      <td>-1.451699e-01</td>\n",
              "      <td>8.524663e-02</td>\n",
              "      <td>6.131154e-32</td>\n",
              "      <td>2.354733e-33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.423396e-01</td>\n",
              "      <td>1.032926e-01</td>\n",
              "      <td>3.868382e-01</td>\n",
              "      <td>-6.265318e-01</td>\n",
              "      <td>-1.818370e-02</td>\n",
              "      <td>-4.918578e-01</td>\n",
              "      <td>3.864416e-01</td>\n",
              "      <td>-2.936680e-01</td>\n",
              "      <td>1.998469e-02</td>\n",
              "      <td>5.766385e-02</td>\n",
              "      <td>6.919976e-02</td>\n",
              "      <td>-2.690194e-32</td>\n",
              "      <td>7.700004e-34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-3.087435e-01</td>\n",
              "      <td>-1.009495e+00</td>\n",
              "      <td>-6.419563e-01</td>\n",
              "      <td>4.476412e-01</td>\n",
              "      <td>-7.227397e-01</td>\n",
              "      <td>-7.004585e-01</td>\n",
              "      <td>-3.049192e-01</td>\n",
              "      <td>-1.473619e-02</td>\n",
              "      <td>1.182262e-02</td>\n",
              "      <td>1.055757e-02</td>\n",
              "      <td>-7.363765e-04</td>\n",
              "      <td>-1.490693e-33</td>\n",
              "      <td>-8.735493e-34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0             1             2             3             4   \\\n",
              "0  -3.220197e-01  2.525227e-01 -1.564564e-01  7.778729e-01 -1.955129e-01   \n",
              "1  -4.224349e-16 -1.600024e-16  6.792698e-17  0.000000e+00 -1.622334e-16   \n",
              "2  -2.966359e+00  2.712726e-02  6.088891e-01 -6.641508e-01 -5.974515e-01   \n",
              "3   3.066357e-01  1.468336e-01  4.457920e-01 -5.581242e-01  6.530943e-02   \n",
              "4  -3.096751e-01  2.595431e+00  9.669401e-02  4.523450e-01 -1.850614e-01   \n",
              "5  -3.745433e-01  5.418049e-01 -2.092535e+00 -8.119706e-01  1.170348e-01   \n",
              "6   0.000000e+00  0.000000e+00  0.000000e+00 -5.196198e-17 -3.244667e-16   \n",
              "7  -3.935669e-01 -7.189521e-02 -4.641707e-01  2.519272e-01 -2.445528e-01   \n",
              "8   3.262375e-01  2.503273e-01  2.800543e-01 -5.695735e-01  1.266431e-01   \n",
              "9  -2.130713e+00 -2.929638e-01 -4.387701e-02  4.051736e-01  1.043595e+00   \n",
              "10 -2.319098e-01 -9.293903e-02 -3.870959e-01  3.718768e-01 -1.743069e-02   \n",
              "11  5.423396e-01  1.032926e-01  3.868382e-01 -6.265318e-01 -1.818370e-02   \n",
              "12  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "13 -3.087435e-01 -1.009495e+00 -6.419563e-01  4.476412e-01 -7.227397e-01   \n",
              "\n",
              "              5             6             7             8             9   \\\n",
              "0   4.841912e-01 -2.197429e-01 -2.530831e-01  7.386638e-02 -1.463219e-02   \n",
              "1   0.000000e+00 -7.384497e-17 -1.419436e-16 -8.731441e-17 -8.995230e-17   \n",
              "2   1.616263e-01  6.179983e-02 -3.136048e-03  1.895443e-02 -2.838913e-02   \n",
              "3  -4.749686e-02 -3.229043e-01  2.158637e-01  1.358611e-01  1.506529e-01   \n",
              "4  -3.411233e-01 -3.855826e-02  3.328887e-02 -7.363256e-03  1.534451e-02   \n",
              "5   9.126031e-02 -5.077466e-02 -4.678996e-02  3.688325e-02  3.287550e-03   \n",
              "6  -1.263394e-16  0.000000e+00  0.000000e+00  2.910480e-17  0.000000e+00   \n",
              "7   1.367196e-01  2.348153e-01  1.161182e-01 -2.348996e-01  1.362912e-01   \n",
              "8  -1.613348e-01 -3.417890e-01  1.540895e-02 -1.585979e-01 -1.917210e-01   \n",
              "9  -3.290386e-01 -8.711071e-02 -3.796881e-02 -1.444465e-02  3.502605e-02   \n",
              "10 -1.479687e-01  4.518882e-01  2.143820e-01  1.241324e-01 -1.451699e-01   \n",
              "11 -4.918578e-01  3.864416e-01 -2.936680e-01  1.998469e-02  5.766385e-02   \n",
              "12  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "13 -7.004585e-01 -3.049192e-01 -1.473619e-02  1.182262e-02  1.055757e-02   \n",
              "\n",
              "              10            11            12   13  \n",
              "0   1.108872e-01 -1.801567e-32 -3.093406e-33  0.0  \n",
              "1  -4.861635e-17  2.254085e-16  7.897691e-18  0.0  \n",
              "2  -8.566457e-03 -1.343028e-32  2.349413e-33  0.0  \n",
              "3   9.473350e-02  7.729667e-32 -2.623560e-33  0.0  \n",
              "4  -1.945994e-02  2.715965e-32  4.717572e-34  0.0  \n",
              "5  -1.713155e-03  1.353554e-32  3.134298e-33  0.0  \n",
              "6   0.000000e+00 -2.605883e-17  6.831491e-17  0.0  \n",
              "7   8.251095e-02 -1.655823e-32 -3.454950e-33  0.0  \n",
              "8   8.382180e-02 -4.872415e-32 -9.767686e-33  0.0  \n",
              "9   1.796569e-02 -2.788218e-32 -6.207624e-33  0.0  \n",
              "10  8.524663e-02  6.131154e-32  2.354733e-33  0.0  \n",
              "11  6.919976e-02 -2.690194e-32  7.700004e-34  0.0  \n",
              "12  0.000000e+00  0.000000e+00  0.000000e+00  0.0  \n",
              "13 -7.363765e-04 -1.490693e-33 -8.735493e-34  0.0  "
            ]
          },
          "execution_count": 419,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.008327</td>\n",
              "      <td>-0.008327</td>\n",
              "      <td>0.110759</td>\n",
              "      <td>0.784912</td>\n",
              "      <td>-3.469447e-18</td>\n",
              "      <td>0.012427</td>\n",
              "      <td>-0.133065</td>\n",
              "      <td>-0.009304</td>\n",
              "      <td>-0.143618</td>\n",
              "      <td>0.016465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060354</td>\n",
              "      <td>-0.417271</td>\n",
              "      <td>-0.020044</td>\n",
              "      <td>-0.118768</td>\n",
              "      <td>-0.047133</td>\n",
              "      <td>-0.136595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003554</td>\n",
              "      <td>-0.133065</td>\n",
              "      <td>0.025891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.193469</td>\n",
              "      <td>0.193469</td>\n",
              "      <td>-0.864275</td>\n",
              "      <td>0.067052</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.009213</td>\n",
              "      <td>0.005122</td>\n",
              "      <td>0.190388</td>\n",
              "      <td>-0.015012</td>\n",
              "      <td>-0.029662</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090794</td>\n",
              "      <td>-0.143849</td>\n",
              "      <td>-0.018930</td>\n",
              "      <td>0.010050</td>\n",
              "      <td>0.291292</td>\n",
              "      <td>0.002177</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020252</td>\n",
              "      <td>0.005122</td>\n",
              "      <td>-0.001988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.019038</td>\n",
              "      <td>0.019038</td>\n",
              "      <td>-0.151502</td>\n",
              "      <td>-0.201028</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>0.022854</td>\n",
              "      <td>0.080179</td>\n",
              "      <td>0.022091</td>\n",
              "      <td>0.010538</td>\n",
              "      <td>0.187091</td>\n",
              "      <td>...</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>-0.456472</td>\n",
              "      <td>0.137498</td>\n",
              "      <td>0.110846</td>\n",
              "      <td>-0.505020</td>\n",
              "      <td>0.067774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017864</td>\n",
              "      <td>0.080179</td>\n",
              "      <td>0.041330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.044935</td>\n",
              "      <td>0.044935</td>\n",
              "      <td>-0.228928</td>\n",
              "      <td>0.151359</td>\n",
              "      <td>2.775558e-17</td>\n",
              "      <td>-0.115317</td>\n",
              "      <td>-0.152870</td>\n",
              "      <td>0.050897</td>\n",
              "      <td>0.094317</td>\n",
              "      <td>0.089294</td>\n",
              "      <td>...</td>\n",
              "      <td>0.263958</td>\n",
              "      <td>0.613576</td>\n",
              "      <td>0.332806</td>\n",
              "      <td>-0.221284</td>\n",
              "      <td>-0.302569</td>\n",
              "      <td>-0.126329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021287</td>\n",
              "      <td>-0.152870</td>\n",
              "      <td>-0.180865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.040139</td>\n",
              "      <td>-0.040139</td>\n",
              "      <td>0.055833</td>\n",
              "      <td>-0.327446</td>\n",
              "      <td>5.551115e-17</td>\n",
              "      <td>0.041722</td>\n",
              "      <td>-0.181434</td>\n",
              "      <td>-0.046903</td>\n",
              "      <td>0.545145</td>\n",
              "      <td>-0.022307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046877</td>\n",
              "      <td>-0.156442</td>\n",
              "      <td>-0.073944</td>\n",
              "      <td>-0.186649</td>\n",
              "      <td>0.042075</td>\n",
              "      <td>-0.186531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.056412</td>\n",
              "      <td>-0.181434</td>\n",
              "      <td>0.045648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.182971</td>\n",
              "      <td>-0.182971</td>\n",
              "      <td>-0.009708</td>\n",
              "      <td>0.090347</td>\n",
              "      <td>-1.110223e-16</td>\n",
              "      <td>-0.155675</td>\n",
              "      <td>0.077095</td>\n",
              "      <td>-0.164167</td>\n",
              "      <td>-0.163940</td>\n",
              "      <td>-0.041350</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.267511</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.480410</td>\n",
              "      <td>-0.005312</td>\n",
              "      <td>-0.077261</td>\n",
              "      <td>0.083208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090152</td>\n",
              "      <td>0.077095</td>\n",
              "      <td>-0.301087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.116329</td>\n",
              "      <td>-0.116329</td>\n",
              "      <td>-0.119850</td>\n",
              "      <td>0.201953</td>\n",
              "      <td>-1.040834e-17</td>\n",
              "      <td>0.043331</td>\n",
              "      <td>-0.016043</td>\n",
              "      <td>-0.097841</td>\n",
              "      <td>-0.046142</td>\n",
              "      <td>-0.036148</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161099</td>\n",
              "      <td>0.362937</td>\n",
              "      <td>-0.654438</td>\n",
              "      <td>0.024646</td>\n",
              "      <td>-0.213166</td>\n",
              "      <td>0.052384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064615</td>\n",
              "      <td>-0.016043</td>\n",
              "      <td>0.188625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.088153</td>\n",
              "      <td>0.088153</td>\n",
              "      <td>0.038638</td>\n",
              "      <td>-0.055955</td>\n",
              "      <td>5.551115e-17</td>\n",
              "      <td>0.524634</td>\n",
              "      <td>0.129568</td>\n",
              "      <td>0.213931</td>\n",
              "      <td>-0.135786</td>\n",
              "      <td>0.227014</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.253925</td>\n",
              "      <td>-0.014094</td>\n",
              "      <td>-0.015818</td>\n",
              "      <td>-0.655516</td>\n",
              "      <td>-0.180204</td>\n",
              "      <td>-0.007994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009391</td>\n",
              "      <td>0.129568</td>\n",
              "      <td>0.024569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.295782</td>\n",
              "      <td>-0.295782</td>\n",
              "      <td>-0.068268</td>\n",
              "      <td>-0.071013</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.056501</td>\n",
              "      <td>0.288762</td>\n",
              "      <td>0.149175</td>\n",
              "      <td>-0.134356</td>\n",
              "      <td>0.034392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242572</td>\n",
              "      <td>-0.022115</td>\n",
              "      <td>-0.235908</td>\n",
              "      <td>-0.180719</td>\n",
              "      <td>0.157047</td>\n",
              "      <td>0.103427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016128</td>\n",
              "      <td>0.288762</td>\n",
              "      <td>-0.446933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.277414</td>\n",
              "      <td>-0.277414</td>\n",
              "      <td>-0.121038</td>\n",
              "      <td>0.146721</td>\n",
              "      <td>3.608225e-16</td>\n",
              "      <td>0.294782</td>\n",
              "      <td>0.058865</td>\n",
              "      <td>0.326713</td>\n",
              "      <td>0.316725</td>\n",
              "      <td>0.223407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.296484</td>\n",
              "      <td>0.011743</td>\n",
              "      <td>-0.004529</td>\n",
              "      <td>0.463525</td>\n",
              "      <td>-0.230463</td>\n",
              "      <td>-0.180192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.016753</td>\n",
              "      <td>0.058865</td>\n",
              "      <td>-0.126342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.106144</td>\n",
              "      <td>0.106144</td>\n",
              "      <td>0.095764</td>\n",
              "      <td>0.148599</td>\n",
              "      <td>2.220446e-16</td>\n",
              "      <td>-0.595888</td>\n",
              "      <td>0.210227</td>\n",
              "      <td>0.085797</td>\n",
              "      <td>0.377326</td>\n",
              "      <td>0.347226</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038953</td>\n",
              "      <td>-0.062163</td>\n",
              "      <td>-0.149354</td>\n",
              "      <td>-0.230711</td>\n",
              "      <td>0.052540</td>\n",
              "      <td>-0.119131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002560</td>\n",
              "      <td>0.210227</td>\n",
              "      <td>-0.094370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.606220</td>\n",
              "      <td>0.132011</td>\n",
              "      <td>0.221424</td>\n",
              "      <td>-0.025183</td>\n",
              "      <td>2.893232e-01</td>\n",
              "      <td>-0.006123</td>\n",
              "      <td>-0.024284</td>\n",
              "      <td>0.237935</td>\n",
              "      <td>-0.147176</td>\n",
              "      <td>0.221247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095165</td>\n",
              "      <td>0.096810</td>\n",
              "      <td>-0.126956</td>\n",
              "      <td>0.320576</td>\n",
              "      <td>-0.090471</td>\n",
              "      <td>0.075882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043357</td>\n",
              "      <td>0.055274</td>\n",
              "      <td>-0.260521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.039152</td>\n",
              "      <td>0.054692</td>\n",
              "      <td>-0.005335</td>\n",
              "      <td>0.156450</td>\n",
              "      <td>-3.938714e-01</td>\n",
              "      <td>-0.038787</td>\n",
              "      <td>0.315989</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.281188</td>\n",
              "      <td>0.117074</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.184147</td>\n",
              "      <td>0.031713</td>\n",
              "      <td>0.042663</td>\n",
              "      <td>0.020763</td>\n",
              "      <td>-0.122678</td>\n",
              "      <td>0.457398</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009046</td>\n",
              "      <td>-0.243206</td>\n",
              "      <td>0.155686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.032256</td>\n",
              "      <td>0.328872</td>\n",
              "      <td>-0.016228</td>\n",
              "      <td>-0.049699</td>\n",
              "      <td>-3.031990e-01</td>\n",
              "      <td>0.058162</td>\n",
              "      <td>0.357212</td>\n",
              "      <td>-0.316377</td>\n",
              "      <td>-0.204198</td>\n",
              "      <td>0.258016</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013097</td>\n",
              "      <td>0.104800</td>\n",
              "      <td>0.034980</td>\n",
              "      <td>0.174620</td>\n",
              "      <td>-0.045152</td>\n",
              "      <td>-0.075422</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003794</td>\n",
              "      <td>0.166986</td>\n",
              "      <td>0.167735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3             4         5         6   \\\n",
              "0  -0.008327 -0.008327  0.110759  0.784912 -3.469447e-18  0.012427 -0.133065   \n",
              "1   0.193469  0.193469 -0.864275  0.067052  0.000000e+00 -0.009213  0.005122   \n",
              "2   0.019038  0.019038 -0.151502 -0.201028  1.110223e-16  0.022854  0.080179   \n",
              "3   0.044935  0.044935 -0.228928  0.151359  2.775558e-17 -0.115317 -0.152870   \n",
              "4  -0.040139 -0.040139  0.055833 -0.327446  5.551115e-17  0.041722 -0.181434   \n",
              "5  -0.182971 -0.182971 -0.009708  0.090347 -1.110223e-16 -0.155675  0.077095   \n",
              "6  -0.116329 -0.116329 -0.119850  0.201953 -1.040834e-17  0.043331 -0.016043   \n",
              "7   0.088153  0.088153  0.038638 -0.055955  5.551115e-17  0.524634  0.129568   \n",
              "8  -0.295782 -0.295782 -0.068268 -0.071013  0.000000e+00 -0.056501  0.288762   \n",
              "9  -0.277414 -0.277414 -0.121038  0.146721  3.608225e-16  0.294782  0.058865   \n",
              "10  0.106144  0.106144  0.095764  0.148599  2.220446e-16 -0.595888  0.210227   \n",
              "11  0.606220  0.132011  0.221424 -0.025183  2.893232e-01 -0.006123 -0.024284   \n",
              "12  0.039152  0.054692 -0.005335  0.156450 -3.938714e-01 -0.038787  0.315989   \n",
              "13 -0.032256  0.328872 -0.016228 -0.049699 -3.031990e-01  0.058162  0.357212   \n",
              "\n",
              "          7         8         9   ...        14        15        16        17  \\\n",
              "0  -0.009304 -0.143618  0.016465  ...  0.060354 -0.417271 -0.020044 -0.118768   \n",
              "1   0.190388 -0.015012 -0.029662  ... -0.090794 -0.143849 -0.018930  0.010050   \n",
              "2   0.022091  0.010538  0.187091  ...  0.571420 -0.456472  0.137498  0.110846   \n",
              "3   0.050897  0.094317  0.089294  ...  0.263958  0.613576  0.332806 -0.221284   \n",
              "4  -0.046903  0.545145 -0.022307  ... -0.046877 -0.156442 -0.073944 -0.186649   \n",
              "5  -0.164167 -0.163940 -0.041350  ... -0.267511  0.015596  0.480410 -0.005312   \n",
              "6  -0.097841 -0.046142 -0.036148  ...  0.161099  0.362937 -0.654438  0.024646   \n",
              "7   0.213931 -0.135786  0.227014  ... -0.253925 -0.014094 -0.015818 -0.655516   \n",
              "8   0.149175 -0.134356  0.034392  ...  0.242572 -0.022115 -0.235908 -0.180719   \n",
              "9   0.326713  0.316725  0.223407  ... -0.296484  0.011743 -0.004529  0.463525   \n",
              "10  0.085797  0.377326  0.347226  ... -0.038953 -0.062163 -0.149354 -0.230711   \n",
              "11  0.237935 -0.147176  0.221247  ... -0.095165  0.096810 -0.126956  0.320576   \n",
              "12  0.007495  0.281188  0.117074  ... -0.184147  0.031713  0.042663  0.020763   \n",
              "13 -0.316377 -0.204198  0.258016  ... -0.013097  0.104800  0.034980  0.174620   \n",
              "\n",
              "          18        19   20        21        22        23  \n",
              "0  -0.047133 -0.136595  0.0  0.003554 -0.133065  0.025891  \n",
              "1   0.291292  0.002177  0.0  0.020252  0.005122 -0.001988  \n",
              "2  -0.505020  0.067774  0.0  0.017864  0.080179  0.041330  \n",
              "3  -0.302569 -0.126329  0.0 -0.021287 -0.152870 -0.180865  \n",
              "4   0.042075 -0.186531  0.0  0.056412 -0.181434  0.045648  \n",
              "5  -0.077261  0.083208  0.0  0.090152  0.077095 -0.301087  \n",
              "6  -0.213166  0.052384  0.0  0.064615 -0.016043  0.188625  \n",
              "7  -0.180204 -0.007994  0.0  0.009391  0.129568  0.024569  \n",
              "8   0.157047  0.103427  0.0 -0.016128  0.288762 -0.446933  \n",
              "9  -0.230463 -0.180192  0.0 -0.016753  0.058865 -0.126342  \n",
              "10  0.052540 -0.119131  0.0  0.002560  0.210227 -0.094370  \n",
              "11 -0.090471  0.075882  0.0  0.043357  0.055274 -0.260521  \n",
              "12 -0.122678  0.457398  0.0 -0.009046 -0.243206  0.155686  \n",
              "13 -0.045152 -0.075422  0.0  0.003794  0.166986  0.167735  \n",
              "\n",
              "[14 rows x 24 columns]"
            ]
          },
          "execution_count": 419,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SVD from scratch\n",
        "q, sigma, vT = np.linalg.svd(ratings_matrix_2_1, full_matrices=False)\n",
        "\n",
        "user_factors = np.matmul(q, np.diag(sigma))\n",
        "pd.DataFrame(user_factors)\n",
        "\n",
        "item_factors = pd.DataFrame(vT)\n",
        "item_factors\n",
        "# user_factors = (q[:,:5])\n",
        "# pd.DataFrame(user_factors)\n",
        "\n",
        "\n",
        "\n",
        "# jj = pd.DataFrame(vT[:5])\n",
        "\n",
        "# jj[14]\n",
        "\n",
        "# ori = np.matmul(user_factors, vT[:5])\n",
        "\n",
        "# pd.DataFrame(ori)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#SVD using surprise p\n",
        "\n",
        "svd = SVD(verbose=True, n_epochs=10)\n",
        "trainset = data.build_full_trainset()\n",
        "svd.fit(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {},
      "outputs": [],
      "source": [
        "svd = TruncatedSVD(n_components=5, n_iter=1)\n",
        "new_ratings = svd.fit_transform(ratings_matrix_2_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14, 5)"
            ]
          },
          "execution_count": 398,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.322020</td>\n",
              "      <td>0.252523</td>\n",
              "      <td>0.156456</td>\n",
              "      <td>-0.777873</td>\n",
              "      <td>-0.195513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.966359</td>\n",
              "      <td>0.027127</td>\n",
              "      <td>-0.608889</td>\n",
              "      <td>0.664151</td>\n",
              "      <td>-0.597452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.306636</td>\n",
              "      <td>0.146834</td>\n",
              "      <td>-0.445792</td>\n",
              "      <td>0.558124</td>\n",
              "      <td>0.065309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.309675</td>\n",
              "      <td>2.595431</td>\n",
              "      <td>-0.096694</td>\n",
              "      <td>-0.452345</td>\n",
              "      <td>-0.185061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.374543</td>\n",
              "      <td>0.541805</td>\n",
              "      <td>2.092535</td>\n",
              "      <td>0.811971</td>\n",
              "      <td>0.117035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.393567</td>\n",
              "      <td>-0.071895</td>\n",
              "      <td>0.464171</td>\n",
              "      <td>-0.251927</td>\n",
              "      <td>-0.244553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.326238</td>\n",
              "      <td>0.250327</td>\n",
              "      <td>-0.280054</td>\n",
              "      <td>0.569574</td>\n",
              "      <td>0.126643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.130713</td>\n",
              "      <td>-0.292964</td>\n",
              "      <td>0.043877</td>\n",
              "      <td>-0.405174</td>\n",
              "      <td>1.043595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.231910</td>\n",
              "      <td>-0.092939</td>\n",
              "      <td>0.387096</td>\n",
              "      <td>-0.371877</td>\n",
              "      <td>-0.017431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.542340</td>\n",
              "      <td>0.103293</td>\n",
              "      <td>-0.386838</td>\n",
              "      <td>0.626532</td>\n",
              "      <td>-0.018184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.308744</td>\n",
              "      <td>-1.009495</td>\n",
              "      <td>0.641956</td>\n",
              "      <td>-0.447641</td>\n",
              "      <td>-0.722740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4\n",
              "0   0.322020  0.252523  0.156456 -0.777873 -0.195513\n",
              "1   0.000000  0.000000  0.000000  0.000000  0.000000\n",
              "2   2.966359  0.027127 -0.608889  0.664151 -0.597452\n",
              "3  -0.306636  0.146834 -0.445792  0.558124  0.065309\n",
              "4   0.309675  2.595431 -0.096694 -0.452345 -0.185061\n",
              "5   0.374543  0.541805  2.092535  0.811971  0.117035\n",
              "6   0.000000  0.000000  0.000000  0.000000  0.000000\n",
              "7   0.393567 -0.071895  0.464171 -0.251927 -0.244553\n",
              "8  -0.326238  0.250327 -0.280054  0.569574  0.126643\n",
              "9   2.130713 -0.292964  0.043877 -0.405174  1.043595\n",
              "10  0.231910 -0.092939  0.387096 -0.371877 -0.017431\n",
              "11 -0.542340  0.103293 -0.386838  0.626532 -0.018184\n",
              "12  0.000000  0.000000  0.000000  0.000000  0.000000\n",
              "13  0.308744 -1.009495  0.641956 -0.447641 -0.722740"
            ]
          },
          "execution_count": 398,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(new_ratings)\n",
        "pd.DataFrame(new_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>asin</th>\n",
              "      <th>B000FOI48G</th>\n",
              "      <th>B000GLRREU</th>\n",
              "      <th>B000NKJIXM</th>\n",
              "      <th>B0010ZBORW</th>\n",
              "      <th>B0013NB7DW</th>\n",
              "      <th>B001E96LUO</th>\n",
              "      <th>B001ET7FZE</th>\n",
              "      <th>B001F51RAG</th>\n",
              "      <th>B001LNODUS</th>\n",
              "      <th>B002GP80EU</th>\n",
              "      <th>...</th>\n",
              "      <th>B00EF1QRMU</th>\n",
              "      <th>B00EYZY6LQ</th>\n",
              "      <th>B00L1I1VMG</th>\n",
              "      <th>B00N2WQ2IW</th>\n",
              "      <th>B00W259T7G</th>\n",
              "      <th>B016V8YWBC</th>\n",
              "      <th>B019809F9Y</th>\n",
              "      <th>B019FWRG3C</th>\n",
              "      <th>B01BNEYGQU</th>\n",
              "      <th>B01E7UKR38</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewerID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1F7YU6O5RU432</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1R1BFJCMWX0Y3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1UQBFCERIP7VJ</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-2.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A22CW0ZHY3NJH8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A25C2M3QF9G7OQ</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2LW5AL0KQ9P1M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2PD27UKAD3Q00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2WW57XX2UVLM6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2ZY49IDE6TY5I</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A39WWMBA0299ZF</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3M6TSEV71537G</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A3S3R88HA0HZG3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A914TQVHI872U</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AOEUN9718KVRD</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "asin            B000FOI48G  B000GLRREU  B000NKJIXM  B0010ZBORW  B0013NB7DW  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432         0.0         0.0   -0.400000    0.000000         0.0   \n",
              "A1R1BFJCMWX0Y3         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A1UQBFCERIP7VJ         0.0         0.0   -0.333333   -2.333333         0.0   \n",
              "A22CW0ZHY3NJH8         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A25C2M3QF9G7OQ         0.6         0.6   -2.400000    0.000000         0.0   \n",
              "A2LW5AL0KQ9P1M         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2PD27UKAD3Q00         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2WW57XX2UVLM6         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A2ZY49IDE6TY5I         0.2         0.2    0.000000    0.000000         0.0   \n",
              "A39WWMBA0299ZF         0.0         0.0    0.000000   -2.000000         0.0   \n",
              "A3M6TSEV71537G         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A3S3R88HA0HZG3         0.0         0.0    0.000000    0.000000         0.0   \n",
              "A914TQVHI872U          0.0         0.0    0.000000    0.000000         0.0   \n",
              "AOEUN9718KVRD          0.0         0.0    0.833333    0.000000         0.0   \n",
              "\n",
              "asin            B001E96LUO  B001ET7FZE  B001F51RAG  B001LNODUS  B002GP80EU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432        -0.4    0.000000         0.0    0.000000         0.0   \n",
              "A1R1BFJCMWX0Y3         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A1UQBFCERIP7VJ         0.0    0.666667         0.0    0.000000         0.0   \n",
              "A22CW0ZHY3NJH8         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A25C2M3QF9G7OQ         0.0    0.000000         0.6    0.000000         0.0   \n",
              "A2LW5AL0KQ9P1M         0.0    0.000000         0.0    0.000000        -0.5   \n",
              "A2PD27UKAD3Q00         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A2WW57XX2UVLM6         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A2ZY49IDE6TY5I         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A39WWMBA0299ZF         0.0    0.000000         0.0    1.000000         0.0   \n",
              "A3M6TSEV71537G         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A3S3R88HA0HZG3         0.0    0.000000         0.0    0.000000         0.0   \n",
              "A914TQVHI872U          0.0    0.000000         0.0    0.000000         0.0   \n",
              "AOEUN9718KVRD          0.0    0.000000         0.0   -0.166667         0.0   \n",
              "\n",
              "asin            ...  B00EF1QRMU  B00EYZY6LQ  B00L1I1VMG  B00N2WQ2IW  \\\n",
              "reviewerID      ...                                                   \n",
              "A1F7YU6O5RU432  ...    0.000000    0.600000    0.600000    0.000000   \n",
              "A1R1BFJCMWX0Y3  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A1UQBFCERIP7VJ  ...    0.000000    0.666667    0.000000    0.666667   \n",
              "A22CW0ZHY3NJH8  ...    0.000000   -1.000000    0.000000    0.000000   \n",
              "A25C2M3QF9G7OQ  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A2LW5AL0KQ9P1M  ...   -1.500000    0.500000   -0.500000    0.000000   \n",
              "A2PD27UKAD3Q00  ...    0.000000    0.000000    0.000000    0.000000   \n",
              "A2WW57XX2UVLM6  ...   -0.333333    0.666667    0.000000    0.000000   \n",
              "A2ZY49IDE6TY5I  ...    0.000000   -0.800000    0.000000    0.000000   \n",
              "A39WWMBA0299ZF  ...    0.000000    1.000000    0.000000    0.000000   \n",
              "A3M6TSEV71537G  ...    0.000000    0.666667   -0.333333   -0.333333   \n",
              "A3S3R88HA0HZG3  ...    0.333333   -0.666667   -0.666667    0.333333   \n",
              "A914TQVHI872U   ...    0.000000    0.000000    0.000000    0.000000   \n",
              "AOEUN9718KVRD   ...    0.000000    0.833333    0.000000    0.000000   \n",
              "\n",
              "asin            B00W259T7G  B016V8YWBC  B019809F9Y  B019FWRG3C  B01BNEYGQU  \\\n",
              "reviewerID                                                                   \n",
              "A1F7YU6O5RU432    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A1R1BFJCMWX0Y3    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A1UQBFCERIP7VJ    0.000000    0.666667         0.0    0.000000    0.666667   \n",
              "A22CW0ZHY3NJH8    1.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A25C2M3QF9G7OQ    0.600000    0.000000         0.0    0.000000    0.000000   \n",
              "A2LW5AL0KQ9P1M    1.500000    0.000000         0.0    0.000000    0.000000   \n",
              "A2PD27UKAD3Q00    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A2WW57XX2UVLM6    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A2ZY49IDE6TY5I    0.200000    0.000000         0.0    0.000000    0.000000   \n",
              "A39WWMBA0299ZF    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A3M6TSEV71537G    0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "A3S3R88HA0HZG3    0.333333    0.000000         0.0    0.000000    0.000000   \n",
              "A914TQVHI872U     0.000000    0.000000         0.0    0.000000    0.000000   \n",
              "AOEUN9718KVRD     0.000000    0.000000         0.0   -0.166667    0.000000   \n",
              "\n",
              "asin            B01E7UKR38  \n",
              "reviewerID                  \n",
              "A1F7YU6O5RU432   -0.400000  \n",
              "A1R1BFJCMWX0Y3    0.000000  \n",
              "A1UQBFCERIP7VJ    0.000000  \n",
              "A22CW0ZHY3NJH8    0.000000  \n",
              "A25C2M3QF9G7OQ    0.000000  \n",
              "A2LW5AL0KQ9P1M    0.000000  \n",
              "A2PD27UKAD3Q00    0.000000  \n",
              "A2WW57XX2UVLM6    0.000000  \n",
              "A2ZY49IDE6TY5I    0.200000  \n",
              "A39WWMBA0299ZF    0.000000  \n",
              "A3M6TSEV71537G    0.000000  \n",
              "A3S3R88HA0HZG3    0.333333  \n",
              "A914TQVHI872U     0.000000  \n",
              "AOEUN9718KVRD     0.000000  \n",
              "\n",
              "[14 rows x 24 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_matrix_2_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'feature_names_in_'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-96-43042e58dbfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_ratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'feature_names_in_'"
          ]
        }
      ],
      "source": [
        "new_ratings.feature_names_in_\n",
        "svd.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOX0_j7tInQT"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFvOOAmQIwD_"
      },
      "source": [
        "### 3.1\n",
        "Define a user-based neighborhood model that takes into account the **mean rating of each user**.\n",
        "Use **cosine as similarity measure** and try to vary the (maximum) number of neighbors to take into\n",
        "account when predicting ratings. Keep Scikit-Surprise’s default setting for all other parameters.\n",
        "Is it better to use 1 or 10 neighbors? You should determine this based on the Root Mean Square\n",
        "Error (RMSE) over 3-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MTjVN9smCflX"
      },
      "outputs": [],
      "source": [
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "data = Dataset.load_from_df(train[['reviewerID', 'asin', 'overall']], reader)\n",
        "\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "# Return a list of ratings that can be used as a testset in the test() method.\n",
        "# The ratings are all the ratings that are not in the trainset, i.e. all the ratings rui where the user u is known, the item i is known, but the rating rui is not in the trainset. \n",
        "anti_test = trainset.build_anti_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3133"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainset.n_ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx1TEeJUC-vZ",
        "outputId": "655650d2-79f5-4565-e233-871723122ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.40131220127533246\n",
            "{'k': 10, 'sim_options': {'name': 'cosine', 'user_based': True}, 'verbose': False}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'k': [1, 10],\n",
        "              'sim_options': {'name': ['cosine'],\n",
        "                              # 'min_support': [1, 5],\n",
        "                              'user_based': [True]},\n",
        "                'verbose': [False]\n",
        "              }\n",
        "\n",
        "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=3)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H4CFKn5IwGQ"
      },
      "outputs": [],
      "source": [
        "## https://bmanohar16.github.io/blog/recsys-evaluation-in-surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL7jcwPVHw9_"
      },
      "source": [
        "### 3.2\n",
        "**Fit the neigborhood-based model** defined in exercise 3.1 on the **full training set** with cosine as\n",
        "similarity measure **bold text** and either 1 or 10 neighbors based on what you found to be better in exercise\n",
        "3.1. Keep Scikit-Surprise’s default setting for all other parameters, but set the random state to 0\n",
        "for comparable results.\n",
        "Use the model to predict the unobserved ratings for the users in the training set. How many\n",
        "predictions are there and what is the average of all the predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "range(0, 981)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainset.all_users()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yOclyexY8qIw",
        "outputId": "9dff1e42-f2de-42f9-f227-76f4b4b8d197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Number of predictions:  54746\n"
          ]
        }
      ],
      "source": [
        "trainset = data.build_full_trainset()\n",
        "anti_test = trainset.build_anti_testset()\n",
        "testset = trainset.build_testset()\n",
        "\n",
        "\n",
        "# data_test = Dataset.load_from_df(test[['reviewerID', 'asin', 'overall']], reader)\n",
        "# trainset_test = data_test.build_full_trainset()\n",
        "\n",
        "sim_options= {'k': '10',\n",
        "              'name': 'cosine',\n",
        "              # 'min_support': [1, 5],\n",
        "              'user_based': [True]}\n",
        "\n",
        "\n",
        "alg_nbm = KNNWithMeans(sim_options= sim_options, random_state = 0, verbose = True)\n",
        "\n",
        "# nbm -> neigborhood based model\n",
        "predictions_nbm = alg_nbm.fit(trainset).test(anti_test)\n",
        "\n",
        "print('Number of predictions: ',len(predictions_nbm) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>iid</th>\n",
              "      <th>r_ui</th>\n",
              "      <th>est</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B00W259T7G</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>3.1</td>\n",
              "      <td>{'actual_k': 2, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B000VV1YOY</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B001LNODUS</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B00006L9LC</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 40, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 40, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54741</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B001QY8QXM</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54742</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B00RZYW4RG</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 1, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54743</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B007V6JNE0</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54744</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B000X2FPXC</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54745</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B00126LYJM</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{'actual_k': 1, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54746 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  uid         iid      r_ui  est  \\\n",
              "0      A105A034ZG9EHO  B00W259T7G  4.722311  3.1   \n",
              "1      A105A034ZG9EHO  B000VV1YOY  4.722311  5.0   \n",
              "2      A105A034ZG9EHO  B001LNODUS  4.722311  5.0   \n",
              "3      A105A034ZG9EHO  B00006L9LC  4.722311  5.0   \n",
              "4      A105A034ZG9EHO  B0012Y0ZG2  4.722311  5.0   \n",
              "...               ...         ...       ...  ...   \n",
              "54741   AZRD4IZU6TBFV  B001QY8QXM  4.722311  5.0   \n",
              "54742   AZRD4IZU6TBFV  B00RZYW4RG  4.722311  5.0   \n",
              "54743   AZRD4IZU6TBFV  B007V6JNE0  4.722311  5.0   \n",
              "54744   AZRD4IZU6TBFV  B000X2FPXC  4.722311  5.0   \n",
              "54745   AZRD4IZU6TBFV  B00126LYJM  4.722311  5.0   \n",
              "\n",
              "                                         details  \n",
              "0       {'actual_k': 2, 'was_impossible': False}  \n",
              "1       {'actual_k': 0, 'was_impossible': False}  \n",
              "2       {'actual_k': 0, 'was_impossible': False}  \n",
              "3      {'actual_k': 40, 'was_impossible': False}  \n",
              "4      {'actual_k': 40, 'was_impossible': False}  \n",
              "...                                          ...  \n",
              "54741   {'actual_k': 0, 'was_impossible': False}  \n",
              "54742   {'actual_k': 1, 'was_impossible': False}  \n",
              "54743   {'actual_k': 0, 'was_impossible': False}  \n",
              "54744   {'actual_k': 0, 'was_impossible': False}  \n",
              "54745   {'actual_k': 1, 'was_impossible': False}  \n",
              "\n",
              "[54746 rows x 5 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "4.628158995296572"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for ease make it a df\n",
        "pred_nbm_df = pd.DataFrame(predictions_nbm)\n",
        "pred_nbm_df\n",
        "np.mean(pred_nbm_df['est'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### note: prediction varies slighttly. is it very relevant?? must ask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copied code!\n",
        "\n",
        "def get_Iu(uid):\n",
        "    \"\"\" return the number of items rated by given user\n",
        "    args: \n",
        "      uid: the id of the user\n",
        "    returns: \n",
        "      the number of items rated by the user\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
        "    except ValueError: # user was not part of the trainset\n",
        "        return 0\n",
        "    \n",
        "def get_Ui(iid):\n",
        "    \"\"\" return number of users that have rated given item\n",
        "    args:\n",
        "      iid: the raw id of the item\n",
        "    returns:\n",
        "      the number of users that have rated the item.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
        "    except ValueError:\n",
        "        return 0\n",
        "    \n",
        "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
        "df['Iu'] = df.uid.apply(get_Iu)\n",
        "df['Ui'] = df.iid.apply(get_Ui)\n",
        "df['err'] = abs(df.est - df.rui)\n",
        "best_predictions = df.sort_values(by='err')[:10]\n",
        "worst_predictions = df.sort_values(by='err')[-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBCjftzsP2bJ"
      },
      "source": [
        "## Exercise 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO30WBk3PxT8"
      },
      "source": [
        "### 4.1\n",
        "Define an SVD model with user and item biases that uses Stochastic Gradient Descend (SGD) to\n",
        "estimate the low-rank matrix based on only observed ratings.\n",
        "Set the number of latent factors to 30 and try to iterate the SGD procedure for different number of\n",
        "epochs. Keep Scikit-Surprise’s default setting for all other parameters.\n",
        "Is it better to run for 100 or 500 epochs? You should determine this based on the RMSE over 3-fold\n",
        "cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJjMmNpP7-d",
        "outputId": "62f68a9b-1f07-4300-c47a-c23079e41e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.40955964147984325\n",
            "{'n_epochs': 500, 'n_factors': 30, 'verbose': False}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'n_epochs': [100, 500],\n",
        "              'n_factors' : [30],\n",
        "              'verbose' : [False]}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2\n",
        "Fit the latent factor model defined in exercise 4.1 on the full training set with 30 latent factors and run for either 100 or 500 epochs based on what you found to be better in exercise 4.1. Keep Scikit- Surprise’s default setting for all other parameters, but set the random state to 0 for comparable results.\n",
        "Use the model to predict the unobserved ratings for the users in the training set. How many predictions are there and what is the average of all the predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w2e7zsQRP8Hd"
      },
      "outputs": [],
      "source": [
        "# trainset = data.build_full_trainset()\n",
        "# anti_test = trainset.build_anti_testset()\n",
        "\n",
        "alg_svd = SVD( n_factors = 30, n_epochs = 500,  random_state= 0, verbose = False)\n",
        "\n",
        "#mdm -> model based model\n",
        "predictions_mbm = alg_svd.fit(trainset).test(anti_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.403720461682837"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_mbm__df = pd.DataFrame(predictions_mbm)\n",
        "np.mean(pred_mbm__df['est'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>iid</th>\n",
              "      <th>r_ui</th>\n",
              "      <th>est</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B00W259T7G</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.704310</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B000VV1YOY</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.727317</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B001LNODUS</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.288815</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B00006L9LC</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54741</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B001QY8QXM</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54742</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B00RZYW4RG</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.587325</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54743</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B007V6JNE0</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>3.427833</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54744</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B000X2FPXC</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.257858</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54745</th>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B00126LYJM</td>\n",
              "      <td>4.722311</td>\n",
              "      <td>4.886127</td>\n",
              "      <td>{'was_impossible': False}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54746 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  uid         iid      r_ui       est  \\\n",
              "0      A105A034ZG9EHO  B00W259T7G  4.722311  4.704310   \n",
              "1      A105A034ZG9EHO  B000VV1YOY  4.722311  4.727317   \n",
              "2      A105A034ZG9EHO  B001LNODUS  4.722311  4.288815   \n",
              "3      A105A034ZG9EHO  B00006L9LC  4.722311  5.000000   \n",
              "4      A105A034ZG9EHO  B0012Y0ZG2  4.722311  5.000000   \n",
              "...               ...         ...       ...       ...   \n",
              "54741   AZRD4IZU6TBFV  B001QY8QXM  4.722311  5.000000   \n",
              "54742   AZRD4IZU6TBFV  B00RZYW4RG  4.722311  4.587325   \n",
              "54743   AZRD4IZU6TBFV  B007V6JNE0  4.722311  3.427833   \n",
              "54744   AZRD4IZU6TBFV  B000X2FPXC  4.722311  4.257858   \n",
              "54745   AZRD4IZU6TBFV  B00126LYJM  4.722311  4.886127   \n",
              "\n",
              "                         details  \n",
              "0      {'was_impossible': False}  \n",
              "1      {'was_impossible': False}  \n",
              "2      {'was_impossible': False}  \n",
              "3      {'was_impossible': False}  \n",
              "4      {'was_impossible': False}  \n",
              "...                          ...  \n",
              "54741  {'was_impossible': False}  \n",
              "54742  {'was_impossible': False}  \n",
              "54743  {'was_impossible': False}  \n",
              "54744  {'was_impossible': False}  \n",
              "54745  {'was_impossible': False}  \n",
              "\n",
              "[54746 rows x 5 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_mbm__df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation of Recommender Systems\n",
        "\n",
        "Based on the same dataset used on previous weeks, let us evaluate the Collaborative Filtering (CF) models implemented last week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import surprise\n",
        "# from surprise import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1\n",
        "\n",
        "1. Load the test set and the predictions made with both Collaborative Filtering models in the previous session. \n",
        "2. Detect those users which are in the training set but not in the test set. Remove their predictions before evaluating the systems.\n",
        "3. Report the Root Mean Square Error (RMSE) for both CF models defined in the previous session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>07 6, 2014</td>\n",
              "      <td>A105A034ZG9EHO</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 180'}</td>\n",
              "      <td>K. Mras</td>\n",
              "      <td>yum</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1404604800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 13, 2013</td>\n",
              "      <td>A10JB7YPWZGRF4</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 45'}</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>I continually get compliments on how wonderful...</td>\n",
              "      <td>Heaven !</td>\n",
              "      <td>1376352000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5030</th>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "      <td>09 6, 2017</td>\n",
              "      <td>A10M2MLE2R0L6K</td>\n",
              "      <td>B019FWRG3C</td>\n",
              "      <td>{'Color:': ' Bath Salts'}</td>\n",
              "      <td>Booklover</td>\n",
              "      <td>I am a bath person.  I always have been.  I lo...</td>\n",
              "      <td>Wonderful lavender scent</td>\n",
              "      <td>1504656000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3560</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>03 16, 2016</td>\n",
              "      <td>A10P0NAKKRYKTZ</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 97'}</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Fantastic shower gel. Not only lathers well bu...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1458086400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4280</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>04 28, 2017</td>\n",
              "      <td>A10ZJZNO4DAVB</td>\n",
              "      <td>B001OHV1H4</td>\n",
              "      <td>{'Size:': ' 43'}</td>\n",
              "      <td>Loeyd</td>\n",
              "      <td>What the hubby wanted</td>\n",
              "      <td>Love it</td>\n",
              "      <td>1493337600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4605</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>08 4, 2014</td>\n",
              "      <td>AZCOSCQG73JZ1</td>\n",
              "      <td>B001OHV1H4</td>\n",
              "      <td>{'Size:': ' B-013'}</td>\n",
              "      <td>william</td>\n",
              "      <td>extremely pleased, very pleasant scent, very l...</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1407110400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4033</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>05 26, 2013</td>\n",
              "      <td>AZD3ON9ZMEGL6</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 124'}</td>\n",
              "      <td>huangweixiong</td>\n",
              "      <td>It smells good, suitable for my needs, the pri...</td>\n",
              "      <td>i love it</td>\n",
              "      <td>1369526400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4471</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 29, 2015</td>\n",
              "      <td>AZFYUPGEE6KLW</td>\n",
              "      <td>B001OHV1H4</td>\n",
              "      <td>{'Size:': ' 483'}</td>\n",
              "      <td>Jo Kamcy</td>\n",
              "      <td>Love this.  I can't find it in the makeup stor...</td>\n",
              "      <td>Love this. I can't find it in the makeup ...</td>\n",
              "      <td>1451347200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4634</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>12 20, 2013</td>\n",
              "      <td>AZJMUP77WBQZQ</td>\n",
              "      <td>B001OHV1H4</td>\n",
              "      <td>{'Size:': ' 329'}</td>\n",
              "      <td>S. Foote</td>\n",
              "      <td>THIS WAS A GIFT PURCHASED LAST YEAR FOR MY DAU...</td>\n",
              "      <td>GIFT</td>\n",
              "      <td>1387497600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3848</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>09 28, 2014</td>\n",
              "      <td>AZRD4IZU6TBFV</td>\n",
              "      <td>B0012Y0ZG2</td>\n",
              "      <td>{'Size:': ' 200'}</td>\n",
              "      <td>Norma Gandy</td>\n",
              "      <td>Like this product very much..it smells great.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1411862400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>949 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      overall  verified   reviewTime      reviewerID        asin  \\\n",
              "3887      5.0      True   07 6, 2014  A105A034ZG9EHO  B0012Y0ZG2   \n",
              "4005      5.0      True  08 13, 2013  A10JB7YPWZGRF4  B0012Y0ZG2   \n",
              "5030      5.0     False   09 6, 2017  A10M2MLE2R0L6K  B019FWRG3C   \n",
              "3560      5.0      True  03 16, 2016  A10P0NAKKRYKTZ  B0012Y0ZG2   \n",
              "4280      5.0      True  04 28, 2017   A10ZJZNO4DAVB  B001OHV1H4   \n",
              "...       ...       ...          ...             ...         ...   \n",
              "4605      5.0      True   08 4, 2014   AZCOSCQG73JZ1  B001OHV1H4   \n",
              "4033      5.0      True  05 26, 2013   AZD3ON9ZMEGL6  B0012Y0ZG2   \n",
              "4471      5.0      True  12 29, 2015   AZFYUPGEE6KLW  B001OHV1H4   \n",
              "4634      5.0      True  12 20, 2013   AZJMUP77WBQZQ  B001OHV1H4   \n",
              "3848      5.0      True  09 28, 2014   AZRD4IZU6TBFV  B0012Y0ZG2   \n",
              "\n",
              "                          style     reviewerName  \\\n",
              "3887          {'Size:': ' 180'}          K. Mras   \n",
              "4005           {'Size:': ' 45'}  Amazon Customer   \n",
              "5030  {'Color:': ' Bath Salts'}        Booklover   \n",
              "3560           {'Size:': ' 97'}  Amazon Customer   \n",
              "4280           {'Size:': ' 43'}            Loeyd   \n",
              "...                         ...              ...   \n",
              "4605        {'Size:': ' B-013'}          william   \n",
              "4033          {'Size:': ' 124'}    huangweixiong   \n",
              "4471          {'Size:': ' 483'}         Jo Kamcy   \n",
              "4634          {'Size:': ' 329'}         S. Foote   \n",
              "3848          {'Size:': ' 200'}      Norma Gandy   \n",
              "\n",
              "                                             reviewText  \\\n",
              "3887                                                yum   \n",
              "4005  I continually get compliments on how wonderful...   \n",
              "5030  I am a bath person.  I always have been.  I lo...   \n",
              "3560  Fantastic shower gel. Not only lathers well bu...   \n",
              "4280                              What the hubby wanted   \n",
              "...                                                 ...   \n",
              "4605  extremely pleased, very pleasant scent, very l...   \n",
              "4033  It smells good, suitable for my needs, the pri...   \n",
              "4471  Love this.  I can't find it in the makeup stor...   \n",
              "4634  THIS WAS A GIFT PURCHASED LAST YEAR FOR MY DAU...   \n",
              "3848      Like this product very much..it smells great.   \n",
              "\n",
              "                                           summary  unixReviewTime vote image  \n",
              "3887                                    Five Stars      1404604800  NaN   NaN  \n",
              "4005                                      Heaven !      1376352000  NaN   NaN  \n",
              "5030                      Wonderful lavender scent      1504656000  NaN   NaN  \n",
              "3560                                    Five Stars      1458086400  NaN   NaN  \n",
              "4280                                       Love it      1493337600  NaN   NaN  \n",
              "...                                            ...             ...  ...   ...  \n",
              "4605                                    Five Stars      1407110400  NaN   NaN  \n",
              "4033                                     i love it      1369526400  NaN   NaN  \n",
              "4471  Love this. I can't find it in the makeup ...      1451347200  NaN   NaN  \n",
              "4634                                          GIFT      1387497600  NaN   NaN  \n",
              "3848                                    Five Stars      1411862400  NaN   NaN  \n",
              "\n",
              "[949 rows x 12 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "# sys.path.append('../')\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# TEST\n",
        "test\n",
        "\n",
        "# # PREDICTIONS\n",
        "\n",
        "\n",
        "# # Detect users from training set that are not in test\n",
        "# nb_users = set([pred.uid for pred in pred_nb_list])\n",
        "# lf_users = set([pred.uid for pred in pred_lf_list])\n",
        "# nb_users_in_pred_but_not_in_test = list(nb_users.difference(set(df_test['reviewerID'])))\n",
        "# lf_users_in_pred_but_not_in_test = list(lf_users.difference(set(df_test['reviewerID'])))\n",
        "# assert nb_users_in_pred_but_not_in_test == lf_users_in_pred_but_not_in_test\n",
        "# print(f\"There are {len(lf_users_in_pred_but_not_in_test)} users in the training set that are not in the test set.\")\n",
        "\n",
        "# # Remove these users' predictions for evaluation\n",
        "# ### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 949 entries, 3887 to 3848\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   overall         949 non-null    float64\n",
            " 1   verified        949 non-null    bool   \n",
            " 2   reviewTime      949 non-null    object \n",
            " 3   reviewerID      949 non-null    object \n",
            " 4   asin            949 non-null    object \n",
            " 5   style           809 non-null    object \n",
            " 6   reviewerName    949 non-null    object \n",
            " 7   reviewText      948 non-null    object \n",
            " 8   summary         948 non-null    object \n",
            " 9   unixReviewTime  949 non-null    int64  \n",
            " 10  vote            92 non-null     object \n",
            " 11  image           17 non-null     object \n",
            "dtypes: bool(1), float64(1), int64(1), object(9)\n",
            "memory usage: 89.9+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "949"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.info()\n",
        "\n",
        "(len(test['reviewerID'].value_counts()))\n",
        "\n",
        "# train[~train.reviewerID.isin(test.reviewerID)].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working with 949 users and 47 items. \n",
            "There are 32 users in training set that are not in the test set. \n",
            "Evaluating the systems with 52988 predictions for users in the test split.\n",
            "RMSE for Neighborhood based Collaborative Filtering: 0.6855655559701531\n",
            "RMSE for Latent Factor based Collaborative Filtering: 0.5485685650260251\n"
          ]
        }
      ],
      "source": [
        "#dataframe with users in train that are not in test dataset.\n",
        "re = train[~train.reviewerID.isin(test.reviewerID)]\n",
        "\n",
        "# # Remove these users' predictions for evaluation\n",
        "upd_pred_mbm__df =pred_mbm__df[pred_mbm__df.uid.isin(test.reviewerID)]\n",
        "upd_pred_nbm_df = pred_nbm_df[pred_nbm_df.uid.isin(test.reviewerID)]\n",
        "\n",
        "\n",
        "print('Working with {} users and {} items. '.format(len(test['reviewerID'].value_counts()), len(test['asin'].value_counts())))\n",
        "print('There are {} users in training set that are not in the test set. '.format(len(re['reviewerID'].value_counts())))\n",
        "print('Evaluating the systems with {} predictions for users in the test split.'.format(len(upd_pred_nbm_df)))\n",
        "\n",
        "\n",
        "# determine RMSE of cleaned predictions dataframe\n",
        "#1st must pass df to list of lists\n",
        "\n",
        "rmse_mbm =surprise.accuracy.rmse(upd_pred_mbm__df.values.tolist(), verbose=False)\n",
        "rmse_nbm =surprise.accuracy.rmse(upd_pred_nbm_df.values.tolist(), verbose=False)\n",
        "\n",
        "print('RMSE for Neighborhood based Collaborative Filtering: {}'.format(rmse_nbm) )\n",
        "\n",
        "print('RMSE for Latent Factor based Collaborative Filtering: {}'.format(rmse_mbm) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2\n",
        "Define a general method to get the top-k recommendations for each user. Print the top-k with k={5, 10} recommendations for the user with ID 'ARARUVZ8RUF5T' and its estimated ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 857,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>iid</th>\n",
              "      <th>r_ui</th>\n",
              "      <th>est</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51330</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B000WR2HB6</td>\n",
              "      <td>0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>{'actual_k': 1, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51296</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B000FOI48G</td>\n",
              "      <td>0</td>\n",
              "      <td>4.675000</td>\n",
              "      <td>{'actual_k': 4, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51286</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B000VV1YOY</td>\n",
              "      <td>0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>{'actual_k': 4, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51309</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B001ET7FZE</td>\n",
              "      <td>0</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>{'actual_k': 5, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51304</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B000PKKAGO</td>\n",
              "      <td>0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>{'actual_k': 1, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51324</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B00EF1QRMU</td>\n",
              "      <td>0</td>\n",
              "      <td>4.470205</td>\n",
              "      <td>{'actual_k': 3, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51298</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B016V8YWBC</td>\n",
              "      <td>0</td>\n",
              "      <td>4.458333</td>\n",
              "      <td>{'actual_k': 4, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51285</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B00W259T7G</td>\n",
              "      <td>0</td>\n",
              "      <td>4.450134</td>\n",
              "      <td>{'actual_k': 18, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51307</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B00CZH3K1C</td>\n",
              "      <td>0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>{'actual_k': 2, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51297</th>\n",
              "      <td>ARARUVZ8RUF5T</td>\n",
              "      <td>B000GLRREU</td>\n",
              "      <td>0</td>\n",
              "      <td>4.233333</td>\n",
              "      <td>{'actual_k': 3, 'was_impossible': False}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 uid         iid  r_ui       est  \\\n",
              "51330  ARARUVZ8RUF5T  B000WR2HB6     0  5.000000   \n",
              "51296  ARARUVZ8RUF5T  B000FOI48G     0  4.675000   \n",
              "51286  ARARUVZ8RUF5T  B000VV1YOY     0  4.666667   \n",
              "51309  ARARUVZ8RUF5T  B001ET7FZE     0  4.600000   \n",
              "51304  ARARUVZ8RUF5T  B000PKKAGO     0  4.500000   \n",
              "51324  ARARUVZ8RUF5T  B00EF1QRMU     0  4.470205   \n",
              "51298  ARARUVZ8RUF5T  B016V8YWBC     0  4.458333   \n",
              "51285  ARARUVZ8RUF5T  B00W259T7G     0  4.450134   \n",
              "51307  ARARUVZ8RUF5T  B00CZH3K1C     0  4.333333   \n",
              "51297  ARARUVZ8RUF5T  B000GLRREU     0  4.233333   \n",
              "\n",
              "                                         details  \n",
              "51330   {'actual_k': 1, 'was_impossible': False}  \n",
              "51296   {'actual_k': 4, 'was_impossible': False}  \n",
              "51286   {'actual_k': 4, 'was_impossible': False}  \n",
              "51309   {'actual_k': 5, 'was_impossible': False}  \n",
              "51304   {'actual_k': 1, 'was_impossible': False}  \n",
              "51324   {'actual_k': 3, 'was_impossible': False}  \n",
              "51298   {'actual_k': 4, 'was_impossible': False}  \n",
              "51285  {'actual_k': 18, 'was_impossible': False}  \n",
              "51307   {'actual_k': 2, 'was_impossible': False}  \n",
              "51297   {'actual_k': 3, 'was_impossible': False}  "
            ]
          },
          "execution_count": 857,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "name = 'ARARUVZ8RUF5T'\n",
        "item = 'B019FWRG3C'\n",
        "\n",
        "def top_rec(df, k):\n",
        "    df = df.sort_values(by= ['uid', 'est'], ascending= False)\n",
        "    return df.groupby('uid').head(k)\n",
        "\n",
        "babe = top_rec(upd_pred_nbm_df, 10)\n",
        "\n",
        "babe.loc[babe['uid'] == name]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Excercise 3\n",
        "Report Precision@k (P@k), MAP@k and the MRR@k with k={5, 10, 20} averaged across users for both CF systems. When computing precision, we consider as relevant items those with an observed rating >= 4.0 (i.e., those items from the test set with a rating >= 4.0). Reflect on the differences obtained. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 850,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Metrics0:\n",
        "\n",
        "  def __init__(self,df,test,k):\n",
        "\n",
        "    self.df = df\n",
        "    self.test = test\n",
        "    self.k = k\n",
        "\n",
        "  def prepare(self):\n",
        "    \"\"\" Join prediction df with test df so the final df has at the ground truth (in this case there's just 1 GT per user)\"\"\"\n",
        "\n",
        "    # upd_pred_nbm_df = top_rec(upd_pred_nbm_df, 10)\n",
        "    # get r_ui column all to zeros\n",
        "    upd_pred_nbm_df = self.df.assign(r_ui=0)\n",
        "\n",
        "    #prepare test df for merging\n",
        "    new_test = self.test[['reviewerID', 'asin', 'overall']]\n",
        "    new_column_list = ['uid', 'iid', 'r_ui']\n",
        "    new_test = new_test.set_axis(new_column_list, axis=1)\n",
        "\n",
        "    #concat predictions df with test df\n",
        "    joint = pd.concat([upd_pred_nbm_df, new_test]).sort_values(by = ['uid', 'iid'])\n",
        "\n",
        "    #make df with just duplicates\n",
        "    duplies = joint[joint.duplicated(subset = ['uid', 'iid'], keep= False)].sort_values(by=['uid', 'r_ui'])\n",
        "\n",
        "    #shift up by 1, so the predictions rows have the real value\n",
        "    duplies['r_ui'] = duplies['r_ui'].shift(-1)\n",
        "\n",
        "    #drop test rows. They no longer matter\n",
        "    no_duplies = duplies[duplies['est'].notna()]\n",
        "\n",
        "\n",
        "    final = pd.concat([joint, no_duplies]).sort_values(by = ['uid', 'iid', 'r_ui']).drop_duplicates(['uid', 'iid'], keep = 'last')#.reset_index(drop=True)\n",
        "    final = final.sort_index(axis = 0)\n",
        "    final = final.sort_values(by= ['uid', 'est'], ascending= False)\n",
        "\n",
        "    #make new column with row index by group\n",
        "    final['group_index'] = final.groupby('uid').cumcount()+1\n",
        "\n",
        "    return final\n",
        "\n",
        "\n",
        "  def get_precision(self):\n",
        "\n",
        "    final = self.prepare()\n",
        "    tt = final.groupby(['uid']).head(self.k)\n",
        "\n",
        "    gg = tt.groupby(['uid']).agg(lambda x: x.ne(0).sum())\n",
        "\n",
        "    return np.mean(gg['r_ui']/self.k)\n",
        "    # return gg\n",
        "\n",
        "\n",
        "  \n",
        "  def hit_rate(self):\n",
        "    \"\"\" Difference from Precision@k is: at the end \n",
        "    -> we have count of non-zeros 'r_ui' per user. (Note: in this exercicise we get AT MOST 1 count per user, because of initial building of test dataset, with just 1 item per user).\n",
        "    -> calculate mean over all users.\n",
        "    In Precision@k:\n",
        "    -> .... same\n",
        "    -> divide the count of non-zeros for a given user by k. \n",
        "    -> caluclate mean over all users  \"\"\"\n",
        "    \n",
        "    final = self.prepare()\n",
        "\n",
        "    # Select only top k rows for each user\n",
        "    tt = final.groupby(['uid']).head(self.k)\n",
        "\n",
        "    # Count number of non-zero elements PER USER. It returns df with many columns (only 'r_ui' matters to us)\n",
        "    gg = tt.groupby(['uid']).agg(lambda x: x.ne(0).sum())\n",
        "\n",
        "    return np.mean(gg['r_ui'])\n",
        "\n",
        "\n",
        "  def get_MRR(self):\n",
        "\n",
        "    final = self.prepare()\n",
        "\n",
        "    final = final.groupby(['uid']).head(self.k)\n",
        "    final = final[final['r_ui'].apply(lambda x: x != 0)]\n",
        "\n",
        "\n",
        "    \n",
        "    return (sum(1/final['group_index']))/ len(self.test)\n",
        "\n",
        "\n",
        "  def get_MAP(self):\n",
        "    \n",
        "    df = self.prepare()\n",
        "\n",
        "    df = df.groupby(['uid']).head(self.k)\n",
        "\n",
        "    #make new column with row index by group\n",
        "    # df['group_index'] = df.groupby('uid').cumcount()\n",
        "\n",
        "    # get rows index that matter to calculate MAP@k\n",
        "    df_new = df[df['r_ui'].apply(lambda x: x != 0)]\n",
        "\n",
        "    return sum(1/(df_new['group_index']))/len(test)\n",
        "\n",
        "    # return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 854,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.039778714436248676"
            ]
          },
          "execution_count": 854,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.17560255416883813"
            ]
          },
          "execution_count": 854,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.17560255416883813"
            ]
          },
          "execution_count": 854,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.7955742887249737"
            ]
          },
          "execution_count": 854,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hola = Metrics0(upd_pred_nbm_df, test, 20)\n",
        "\n",
        "hola.get_precision()\n",
        "hola.get_MAP()\n",
        "hola.get_MRR()\n",
        "\n",
        "hola.hit_rate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 855,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.037776606954689256"
            ]
          },
          "execution_count": 855,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.13664170284574037"
            ]
          },
          "execution_count": 855,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.13664170284574037"
            ]
          },
          "execution_count": 855,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.7555321390937829"
            ]
          },
          "execution_count": 855,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "hola = Metrics0(upd_pred_mbm__df, test, 20)\n",
        "\n",
        "hola.get_precision()\n",
        "hola.get_MAP()\n",
        "hola.get_MRR()\n",
        "\n",
        "hola.hit_rate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Excercise 4\n",
        "\n",
        "Based on the top-5, top-10 and top-20 predictions from Exercise 2, compute the systems’ hit rate averaged over the total number of users in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s5yo2Dqjqef"
      },
      "source": [
        "Please, note that this notebook is intended to be run in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkMH-1WClvTd"
      },
      "outputs": [],
      "source": [
        "# # Mount drive and define path to the data folder (from your Google Drive)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# datapath = 'drive/MyDrive/data/amazon_reviews/All_Beauty/'\n",
        "# train_file = 'training.pkl'\n",
        "# test_file = 'test.pkl'\n",
        "# meta_file = 'meta_All_Beauty.json'\n",
        "# uy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%` not found.\n"
          ]
        }
      ],
      "source": [
        "# % wget http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_All_Beauty.json.gz\n",
        "\n",
        "# http://deepyeti.ucsd.edu/jianmo/amazon/sample/meta_Computers.json.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'meta_All_Beauty_5.json.gz'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-b277e1335012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmeta_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'meta_All_Beauty_5.json.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-6-a2f262b0ea70>\u001b[0m in \u001b[0;36mgetDF\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-6-a2f262b0ea70>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'meta_All_Beauty_5.json.gz'"
          ]
        }
      ],
      "source": [
        "meta_df = getDF('meta_All_Beauty_5.json.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIYb2Pxi6_Ie"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Load the [metadata file](https://nijianmo.github.io/amazon/index.html) and discard any item that was not rated by our subset of users (nor in training or test sets). Apply preprocessing (stemming and stopwords removal) to clean up the text from the \"title\". Report the vocabulary size before and after the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKbUQSlc65kO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# Load TRAIN and TEST sets \n",
        "\n",
        "# Load the METADATA (ITEMS)\n",
        "\n",
        "# Discard duplicates\n",
        "\n",
        "# Discard items that weren't rated by our subset of users\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd0RbH-k9y1H"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blr1jgoHLbFU"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Representation in vector spaces.\n",
        "\n",
        "### 2.1\n",
        "\n",
        "Represent all the products from Exercise 1 in a TF-IDF space. Interpret the meaning of the TF-IDF matrix dimensions.\n",
        "\n",
        "Tip: You may use the library [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDndolvDLznV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gnTVM0EV_2d"
      },
      "source": [
        "### 2.2\n",
        "\n",
        "Compute and the cosine similarity between products with asin 'B000FI4S1E', 'B000LIBUBY' and 'B000W0C07Y'. Take a look at their features to see whether results make sense with their characteristics. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO_OHMY8PWbO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8jRhWhZQWe"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "Representation in vector spaces with contextual Word Embeddings.\n",
        "\n",
        "### 3.1.\n",
        "\n",
        "Represent all the products from Exercise 1 in a vector space using embeddings from a pre-trained BERT model. The final embedding of a product should be the average of the word embeddings from all the words in the 'title'. What is the vocabulary size of the model? What are the dimensions of the last hidden state?\n",
        "\n",
        "Tip: you may install the transformers library and use their pretrained [BERT model uncased](https://huggingface.co/bert-base-uncased)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHIjJ-LbTB3H"
      },
      "outputs": [],
      "source": [
        "# LOAD TRANSFORMER\n",
        "\"\"\"\n",
        "If you plan on using a pretrained model, it’s important to use the associated \n",
        "pretrained tokenizer: it will split the text you give it in tokens the same way\n",
        "for the pretraining corpus, and it will use the same correspondence\n",
        "token to index (that we usually call a vocab) as during pretraining.\n",
        "\"\"\"\n",
        "\n",
        "# % pip install transformers\n",
        "import torch\n",
        "import transformers\n",
        "assert transformers.__version__ > '4.0.0'\n",
        "\n",
        "from transformers import BertModel, BertTokenizerFast\n",
        "\n",
        "# set-up environment\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "\n",
        "modelname = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizerFast.from_pretrained(modelname)\n",
        "model = BertModel.from_pretrained(modelname).to(DEVICE)\n",
        "\n",
        "# Print out the vocabulary size\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Symyv5U07x"
      },
      "outputs": [],
      "source": [
        "# REPRESENT PRODUCTS IN A VECTOR SPACE\n",
        "\n",
        "\n",
        "def batch_encoding(sentences):\n",
        "    # Since we're using padding, we need to provide the attention masks to our\n",
        "    # model. Otherwise it doesn't know which tokens it should not attend to. \n",
        "    inputs = # <YOUR CODE HERE>\n",
        "    # print(inputs) # Look at the padding and attention_mask\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = # <YOUR CODE HERE>\n",
        "\n",
        "    return inputs, last_hidden_states\n",
        "  \n",
        "encoded_inputs, title_last_hidden_states = batch_encoding( # <YOUR CODE HERE> )\n",
        "\n",
        "\"\"\"\n",
        "Note that the control token [CLS] has been added \n",
        "at the beginning of each sentence, and [SEP] at the end. \n",
        "\"\"\"\n",
        "\n",
        "# Now, let's mask out the padding tokens and compute the embedding vector of each product\n",
        "\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwRBr2HP0Zdt"
      },
      "source": [
        "### 3.2.\n",
        "\n",
        "Compute and the cosine similarity between products with asin 'B000FI4S1E', 'B000LIBUBY' and 'B000W0C07Y'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaHxSLHqItNs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Session_1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
